{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Eager execution: True\n",
      "Keras version: 2.2.4-tf\n",
      "Cuda version: 10.1\n",
      "Cudnn version: 7\n",
      "Num Physical GPUs Available:  0\n",
      "Num Logical GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, MaxPool2D, Activation\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import get_custom_objects\n",
    "from tensorflow.python.platform import build_info as tf_build_info\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "print(\"Cuda version: {}\".format(tf_build_info.cuda_version_number))\n",
    "print(\"Cudnn version: {}\".format(tf_build_info.cudnn_version_number))\n",
    "print(\"Num Physical GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num Logical GPUs Available: \", len(tf.config.experimental.list_logical_devices('GPU')))\n",
    "\n",
    "\n",
    "NETWORK_W          = 416\n",
    "NETWORK_H          = 416\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# needs to be defined as activation class otherwise error\n",
    "# AttributeError: 'Activation' object has no attribute '__name__'    \n",
    "class Mish(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'mish'\n",
    "\n",
    "\n",
    "def mysoftplus(x):\n",
    "\n",
    "    mask_min = tf.cast((x<-20.0),tf.float32)\n",
    "    ymin = mask_min*tf.math.exp(x)\n",
    "\n",
    "    mask_max = tf.cast((x>20.0),tf.float32)\n",
    "    ymax = mask_max*x\n",
    "    \n",
    "    mask= tf.cast((abs(x)<=20.0),tf.float32)\n",
    "    y = mask*tf.math.log(tf.math.exp(x) + 1.0)\n",
    "    \n",
    "    return(ymin+ymax+y)    \n",
    "        \n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return (x* tf.math.tanh(mysoftplus(x)))\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "get_custom_objects().update({'mish': Mish(mish)})\n",
    "\n",
    "def _conv_block(inp, convs, skip=False):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    \n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)), name='zerop_' + str(conv['layer_idx']))(x)  # peculiar padding as darknet prefer left and top\n",
    "        \n",
    "        x = Conv2D(conv['filter'], \n",
    "                   conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='convn_' + str(conv['layer_idx']) if conv['bnorm'] else 'conv_' + str(conv['layer_idx']),\n",
    "                   use_bias=True)(x)\n",
    "        \n",
    "        if conv['bnorm']: x = BatchNormalization(name='BN_' + str(conv['layer_idx']))(x)    \n",
    "        \n",
    "        if conv['activ'] == 1: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "        if conv['activ'] == 2: x = Activation('mish', name='mish_' + str(conv['layer_idx']))(x) \n",
    "            \n",
    "    return add([skip_connection, x],  name='add_' + str(conv['layer_idx']+1)) if skip else x\n",
    "\n",
    "def make_yolov3_tiny_model():\n",
    "        \n",
    "    input_image = Input(shape=(NETWORK_H, NETWORK_W, 3), name='input_0')\n",
    "\n",
    "    # Layer  0\n",
    "    x = _conv_block(input_image, [{'filter': 16, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 0}])\n",
    "    \n",
    "    # Layer  1\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_1')(x)\n",
    "    \n",
    "    # Layer  2\n",
    "    x = _conv_block(x, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 2}])\n",
    "  \n",
    "    # Layer  3\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_3')(x)\n",
    "    \n",
    "    # Layer  4\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 4}])   \n",
    "\n",
    "    # Layer  5\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_5')(x)\n",
    "    \n",
    "    # Layer  6\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 6}])   \n",
    "    \n",
    "    # Layer  7\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_7')(x)\n",
    "    \n",
    "    # Layer  8\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 8}])   \n",
    "    layer_8 = x\n",
    "    \n",
    "    # Layer  9\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_9')(x)\n",
    "    \n",
    "    # Layer  10\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 10}])\n",
    "    layer_10 = x\n",
    "    \n",
    "    # Layer  11\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=1, padding='same', name = 'max_11')(x)\n",
    "    \n",
    "    # Layer  12\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 12}])\n",
    "\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    # Layer  13\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 13}]) \n",
    "    layer_13 = x\n",
    "        \n",
    "    # Layer  14\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 14}])     \n",
    "    \n",
    "    # Layer  15\n",
    "    x = _conv_block(x, [{'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 0, 'layer_idx': 15}])    \n",
    "    \n",
    "    # Layer  16\n",
    "    yolo_16 = x\n",
    "    \n",
    "    \n",
    "    # Layer  17\n",
    "    x = layer_13\n",
    "\n",
    "    # Layer  18\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 18}])\n",
    "   \n",
    "    # Layer  19\n",
    "    x = UpSampling2D(size=(2, 2), name = 'upsamp_19')(x)\n",
    "\n",
    "    # Layer  20\n",
    "    x = concatenate([layer_8, x],  name='concatenate_20')\n",
    "    \n",
    "    # Layer  21\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 21}])     \n",
    "    \n",
    "    # Layer  22\n",
    "    x = _conv_block(x, [{'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 0, 'layer_idx': 22}])    \n",
    "    \n",
    "    # Layer  23\n",
    "    yolo_23 = x   \n",
    "                                      \n",
    "    model = Model(input_image, [yolo_16, yolo_23], name = 'Yolo_v3_tiny')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = make_yolov3_tiny_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import struct\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                print(\"reading 64 bytes\")\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                print(\"reading 32 bytes\")\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        count = 0\n",
    "        ncount = 0\n",
    "        for i in range(23):\n",
    "            try:\n",
    "\n",
    "                conv_layer = model.get_layer('convn_' + str(i))\n",
    "                filter = conv_layer.kernel.shape[-1]\n",
    "                nweights = np.prod(conv_layer.kernel.shape) # kernel*kernel*c*filter\n",
    "                \n",
    "                print(\"loading weights of convolution #\" + str(i)+ \"- nb parameters: \"+str(nweights+filter))             \n",
    "                \n",
    "                if i  in [15, 22]:\n",
    "                    print(\"Special processing for layer \"+ str(i))\n",
    "                    bias  = self.read_bytes(filter) # bias\n",
    "                    weights = self.read_bytes(nweights) # weights\n",
    "                \n",
    "                else:                    \n",
    "                    bias  = self.read_bytes(filter) # bias\n",
    "                    scale = self.read_bytes(filter) # scale\n",
    "                    mean  = self.read_bytes(filter) # mean\n",
    "                    var   = self.read_bytes(filter) # variance\n",
    "                    weights = self.read_bytes(nweights) # weights\n",
    "                    \n",
    "                    bias = bias - scale  * mean / (np.sqrt(var + 0.00001)) #normalize bias\n",
    "\n",
    "                    weights = np.reshape(weights,(filter,int(nweights/filter)))  #normalize weights\n",
    "                    A = scale / (np.sqrt(var + 0.00001))\n",
    "                    A= np.expand_dims(A,axis=0)\n",
    "                    weights = weights* A.T\n",
    "                    weights = np.reshape(weights,(nweights))\n",
    "                \n",
    "\n",
    "                weights = weights.reshape(list(reversed(conv_layer.get_weights()[0].shape)))                 \n",
    "                weights = weights.transpose([2,3,1,0])\n",
    "                \n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    a=conv_layer.set_weights([weights, bias])\n",
    "                else:    \n",
    "                    a=conv_layer.set_weights([weights])\n",
    "                \n",
    "                count = count+1\n",
    "                ncount = ncount+nweights+filter\n",
    "             \n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i)) \n",
    "        \n",
    "        print(count, \"Conv normalized layers loaded \", ncount, \" parameters\")\n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 64 bytes\n",
      "loading weights of convolution #0- nb parameters: 448\n",
      "no convolution #1\n",
      "loading weights of convolution #2- nb parameters: 4640\n",
      "no convolution #3\n",
      "loading weights of convolution #4- nb parameters: 18496\n",
      "no convolution #5\n",
      "loading weights of convolution #6- nb parameters: 73856\n",
      "no convolution #7\n",
      "loading weights of convolution #8- nb parameters: 295168\n",
      "no convolution #9\n",
      "loading weights of convolution #10- nb parameters: 1180160\n",
      "no convolution #11\n",
      "loading weights of convolution #12- nb parameters: 4719616\n",
      "loading weights of convolution #13- nb parameters: 262400\n",
      "loading weights of convolution #14- nb parameters: 1180160\n",
      "loading weights of convolution #15- nb parameters: 130815\n",
      "Special processing for layer 15\n",
      "no convolution #16\n",
      "no convolution #17\n",
      "loading weights of convolution #18- nb parameters: 32896\n",
      "no convolution #19\n",
      "no convolution #20\n",
      "loading weights of convolution #21- nb parameters: 884992\n",
      "loading weights of convolution #22- nb parameters: 65535\n",
      "Special processing for layer 22\n",
      "13 Conv normalized layers loaded  8849182  parameters\n"
     ]
    }
   ],
   "source": [
    "# Get and compute the weights\n",
    "weight_reader = WeightReader('models/yolo/yolov3-tiny.weights')\n",
    "weight_reader.load_weights(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle Windows\n",
      " Le num‚ro de s‚rie du volume est CCDC-AB26\n",
      "\n",
      " R‚pertoire de C:\\Users\\edh\\yolo4\\Yolov-4\\models\\yolo\n",
      "\n",
      "11/07/2020  13:12        35ÿ584ÿ360 yolov3-tiny.h5\n",
      "11/07/2020  12:31       258ÿ880ÿ344 yolov4.h5\n",
      "               2 fichier(s)      294ÿ464ÿ704 octets\n",
      "               0 R‚p(s)  295ÿ037ÿ321ÿ216 octets libres\n"
     ]
    }
   ],
   "source": [
    "# save the model to file\n",
    "! rm models\\yolo\\yolov3-tiny.h5\n",
    "\n",
    "model.save('models/yolo/yolov3-tiny.h5')\n",
    "! dir models\\yolo\\*.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edh\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model, Model\n",
    "yolo_model = load_model(\"models/yolo/yolov3-tiny.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  input_0  trainable:  False\n",
      "layer  convn_0  trainable:  False\n",
      "layer  BN_0  trainable:  False\n",
      "layer  leaky_0  trainable:  False\n",
      "layer  max_1  trainable:  False\n",
      "layer  convn_2  trainable:  False\n",
      "layer  BN_2  trainable:  False\n",
      "layer  leaky_2  trainable:  False\n",
      "layer  max_3  trainable:  False\n",
      "layer  convn_4  trainable:  False\n",
      "layer  BN_4  trainable:  False\n",
      "layer  leaky_4  trainable:  False\n",
      "layer  max_5  trainable:  False\n",
      "layer  convn_6  trainable:  False\n",
      "layer  BN_6  trainable:  False\n",
      "layer  leaky_6  trainable:  False\n",
      "layer  max_7  trainable:  False\n",
      "layer  convn_8  trainable:  False\n",
      "layer  BN_8  trainable:  False\n",
      "layer  leaky_8  trainable:  False\n",
      "layer  max_9  trainable:  False\n",
      "layer  convn_10  trainable:  False\n",
      "layer  BN_10  trainable:  False\n",
      "layer  leaky_10  trainable:  False\n",
      "layer  max_11  trainable:  False\n",
      "layer  convn_12  trainable:  False\n",
      "layer  BN_12  trainable:  False\n",
      "layer  leaky_12  trainable:  False\n",
      "layer  convn_13  trainable:  True\n",
      "layer  BN_13  trainable:  True\n",
      "layer  leaky_13  trainable:  True\n",
      "layer  convn_18  trainable:  True\n",
      "layer  BN_18  trainable:  True\n",
      "layer  leaky_18  trainable:  True\n",
      "layer  upsamp_19  trainable:  True\n",
      "layer  concatenate_20  trainable:  True\n",
      "layer  convn_14  trainable:  True\n",
      "layer  convn_21  trainable:  True\n",
      "layer  BN_14  trainable:  True\n",
      "layer  BN_21  trainable:  True\n",
      "layer  leaky_14  trainable:  True\n",
      "layer  leaky_21  trainable:  True\n",
      "layer  convn_15  trainable:  True\n",
      "layer  convn_22  trainable:  True\n",
      "layer  BN_15  trainable:  True\n",
      "layer  BN_22  trainable:  True\n"
     ]
    }
   ],
   "source": [
    "# Freeze the backbone\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = \"convn_13\"\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "train = False\n",
    "for l in yolo_model.layers:\n",
    "  if l.name == fine_tune_at:\n",
    "        train = True        \n",
    "  l.trainable =  train\n",
    "    \n",
    "\n",
    "# Display the trainable indicator\n",
    "for l in yolo_model.layers:\n",
    "    print(\"layer \",l.name, \" trainable: \", l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(labels_path):\n",
    "    with open(labels_path) as f:\n",
    "        labels = f.readlines()\n",
    "    labels = [c.strip() for c in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "nb labels:  80\n"
     ]
    }
   ],
   "source": [
    "# Load the labels\n",
    "labels = read_labels(\"models/yolo/coco_classes.txt\")\n",
    "print(labels)\n",
    "print(\"nb labels: \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_W        = 416\n",
    "NETWORK_H        = 416\n",
    "NB_BOX           = 3\n",
    "NB_CLASS         = len(labels)\n",
    "OBJ_THRESHOLD    = 0.3\n",
    "NMS_THRESHOLD    = 0.3\n",
    "grids = [(13,13), (26,26)]\n",
    "anchors = [[81,82,  135,169,  344,319], [10,14,  23,27,  37,58]]\n",
    "scales_x_y = [1.0, 1.0]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 32\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "     \n",
    "        \n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "    \n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    " \n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    " \n",
    "        return self.label\n",
    " \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    " \n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "def convert(image_wh, box, grid_w, grid_h, Boxanchor, yolo_id):\n",
    "    dw = image_wh[0]/ grid_w\n",
    "    dh = image_wh[1]/ grid_h\n",
    "    center_x = (box[0] + box[1])/2.0\n",
    "    center_x = center_x / dw\n",
    "    center_y = (box[2] + box[3])/2.0\n",
    "    center_y = center_y / dh\n",
    "    \n",
    "    grid_x = int(np.floor(center_x))\n",
    "    grid_y = int(np.floor(center_y))\n",
    "    \n",
    "    if grid_x < grid_w and grid_y < grid_h:\n",
    "        w = (box[1] - box[0]) / dw\n",
    "        h = (box[3] - box[2]) / dh\n",
    "        \n",
    "        # find the anchor that best predicts this box\n",
    "        best_anchor = -1\n",
    "        max_iou     = -1\n",
    "    \n",
    "        shifted_box = BoundBox(0,0,w,h)\n",
    "    \n",
    "        for i in range(len(anchors[yolo_id])//2):\n",
    "            iou    = bbox_iou(shifted_box, Boxanchor[i])                   \n",
    "            if max_iou < iou:\n",
    "                best_anchor = i\n",
    "                max_iou     = iou\n",
    "    \n",
    "        return (center_x,center_y,w,h,grid_x,grid_y,best_anchor)\n",
    "    \n",
    "    else: # not compatible with the grid size\n",
    "        return (0,0,0,0,0,0,-1)\n",
    "    \n",
    "\n",
    "def convert_annotation(year, image_set, image_id, grid_w, grid_h, Boxanchor, yolo_id, VOC_path):\n",
    "    in_file = open(VOC_path+'VOC%s\\\\Annotations\\\\%s.xml'%(year, image_id))\n",
    "    out_file = open('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_%s\\\\%s.txt'%(year, image_set, yolo_id, image_id), 'w')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    image_w = int(size.find('width').text)\n",
    "    image_h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in labels or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = labels.index(cls)\n",
    "        \n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((image_w,image_h), b, grid_w, grid_h, Boxanchor, yolo_id)\n",
    "        \n",
    "        if bb[-1] != -1:\n",
    "            out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "\n",
    "def build_label_files (year, image_set, VOC_path):\n",
    "    yolo_id = 0\n",
    "    \n",
    "    for grid_w, grid_h in grids:\n",
    "        print(\"grid :\",grid_w, grid_h)\n",
    "\n",
    "        Boxanchor= [BoundBox(0, 0, anchors[yolo_id][2*i], anchors[yolo_id][2*i+1]) for i in range(int(len(anchors[yolo_id])//2))]\n",
    "       \n",
    "        if not os.path.exists('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_%s\\\\' %(year, image_set, yolo_id)):\n",
    "            os.makedirs('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_%s\\\\' %(year, image_set, yolo_id))\n",
    "        \n",
    "        image_ids = open(VOC_path+'VOC%s\\\\ImageSets\\\\Main\\\\%s.txt'%(year, image_set)).read().strip().split()\n",
    "\n",
    "        for image_id in image_ids:\n",
    "            convert_annotation(year, image_set, image_id, grid_w, grid_h, Boxanchor, yolo_id, VOC_path)\n",
    "            \n",
    "        yolo_id+=1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid : 13 13\n",
      "grid : 26 26\n"
     ]
    }
   ],
   "source": [
    "# Build the label files for training\n",
    "VOC_path = '..\\\\train\\\\VOCdevkit\\\\'\n",
    "build_label_files ('2012', 'train', VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid : 13 13\n",
      "grid : 26 26\n"
     ]
    }
   ],
   "source": [
    "# Build the label files for validation\n",
    "build_label_files ('2012', 'val', VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, interpolation = 'bilinear', target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    \n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train (year, image_set, nb_train, VOC_path):\n",
    " \n",
    "    train_x  = np.zeros ((nb_train, NETWORK_H, NETWORK_W, 3), dtype=np.float32)\n",
    "    train_y0 = np.zeros ((nb_train, grids[0][1], grids[0][0], NB_BOX,(4+1+NB_CLASS)), dtype=np.float32)\n",
    "    train_y1 = np.zeros ((nb_train, grids[1][1], grids[1][0], NB_BOX,(4+1+NB_CLASS)), dtype=np.float32)\n",
    "    bc = 0 \n",
    "        \n",
    "    image_ids = open(VOC_path+'VOC%s\\\\ImageSets\\\\Main\\\\%s.txt'%(year, image_set)).read().strip().split()\n",
    "\n",
    "    \n",
    "    for image_id in image_ids:        \n",
    "        # Pre-process the image train_x\n",
    "        img_filename = VOC_path+'VOC%s\\\\JPEGImages\\\\%s.jpg'%(year, image_id)\n",
    "        image, image_w, image_h = load_image_pixels(img_filename, (NETWORK_W, NETWORK_H))\n",
    "        train_x[bc,:,:,:] = image\n",
    "        \n",
    "        # build true predict train_y0 and box b0\n",
    "        labels_file = open('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_0\\\\%s.txt'%(year, image_set, image_id), 'r')\n",
    "        \n",
    "        rec = np.fromfile(labels_file, dtype=np.float32, sep = \" \")\n",
    "        for i in range(len(rec)//8):\n",
    "            classid,x,y,w,h,grid_x,grid_y,best_anchor = rec[8*i:8*(i+1)]\n",
    "            train_y0[bc, int(grid_y),int(grid_x),int(best_anchor), 0:4] = x,y,w,h\n",
    "            train_y0[bc, int(grid_y),int(grid_x),int(best_anchor), 4] = 1.\n",
    "            train_y0[bc, int(grid_y),int(grid_x),int(best_anchor), 5+ int(classid)] = 0.9 #Class label smoothing, use 0.9 instead of 1.0 in order to mitigate overfitting.\n",
    "            \n",
    "        # build true predict train_y1 and box b1\n",
    "        labels_file = open('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_1\\\\%s.txt'%(year, image_set, image_id), 'r')\n",
    "        \n",
    "        rec = np.fromfile(labels_file, dtype=np.float32, sep = \" \")\n",
    "        true_box_index = 0\n",
    "        for i in range(len(rec)//8):\n",
    "            classid,x,y,w,h,grid_x,grid_y,best_anchor = rec[8*i:8*(i+1)]\n",
    "            train_y1[bc, int(grid_y),int(grid_x),int(best_anchor), 0:4] = x,y,w,h\n",
    "            train_y1[bc, int(grid_y),int(grid_x),int(best_anchor), 4] = 1.\n",
    "            train_y1[bc, int(grid_y),int(grid_x),int(best_anchor), 5+ int(classid)] = 0.9 #Class label smoothing, use 0.9 instead of 1.0 in order to mitigate overfitting.\n",
    "             \n",
    "        bc+=1\n",
    "        if bc == nb_train:\n",
    "            break\n",
    "            \n",
    "    return(train_x,  [train_y0,train_y1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the data for training\n",
    "VOC_path = '..\\\\train\\\\VOCdevkit\\\\'\n",
    "nb_data_for_training= 640\n",
    "train_x, train_y = build_train('2012', 'train', (nb_data_for_training//BATCH_SIZE)*BATCH_SIZE, VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the data for validation\n",
    "nb_data_for_validation= 320\n",
    "val_x, val_y = build_train('2012', 'val', (nb_data_for_validation//BATCH_SIZE)*BATCH_SIZE, VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "   \n",
    "    print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "    print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "    print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "   \n",
    "    print(y_pred.shape)\n",
    "    grid_h, grid_w = y_pred.shape[1:3] \n",
    "    print (\"grid_h, grid_w\",grid_h, grid_w)\n",
    "    \n",
    "    if grid_h == 13:\n",
    "        anchor = anchors[0]\n",
    "    else:    \n",
    "        anchor = anchors[1]     \n",
    "        \n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    print (\"mask_shape\",mask_shape)\n",
    "\n",
    "    \n",
    "    cell_x = tf.cast((tf.reshape(tf.tile(tf.range(grid_w), [grid_h]), (1, grid_h, grid_w, 1, 1))),dtype=tf.float32)\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, NB_BOX, 1])\n",
    "    \n",
    "    \n",
    "    ######  prediction\n",
    "    y_pred = tf.reshape(y_pred, (BATCH_SIZE, grid_h, grid_w, NB_BOX, NB_CLASS+5))\n",
    "\n",
    "    ### adjust x and y  \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) # x, y)\n",
    "    pred_box_xy = pred_box_xy + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(anchor, [1,1,1,NB_BOX,2])\n",
    "    \n",
    "    ### adjust objectness\n",
    "    pred_box_obj = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = tf.sigmoid(y_pred[..., 5:])\n",
    "    \n",
    "    \n",
    "    ######  true\n",
    "    y_true = tf.reshape(y_true, (BATCH_SIZE, grid_h, grid_w, NB_BOX, NB_CLASS+5))\n",
    "    print (\"y_true\", y_true.shape)\n",
    "\n",
    "    ### adjust x and y  \n",
    "    true_box_xy = y_true[..., :2] # x, y\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4]\n",
    "    \n",
    "    ### adjust objectness\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "\n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    \n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas + 1e-10\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "   \n",
    "    true_box_obj = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "\n",
    "    \n",
    "    \n",
    "    ######  coefficients   \n",
    "   \n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    ### is 1 when there is an object in the cell i, else 0.\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    print(\"sum coord_mask\",tf.reduce_sum(coord_mask))\n",
    "    \n",
    "    ### objectness mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    for i in range(BATCH_SIZE):\n",
    "        bd = y_true[i,:,:,:,:4]\n",
    "        nozero = tf.not_equal(bd, tf.zeros((grid_h, grid_w, NB_BOX, 4)))\n",
    "        bdd = tf.boolean_mask(bd, nozero)\n",
    "        s=tf.squeeze(tf.size(bdd)//4)\n",
    "        c= tf.zeros((50-s,4))\n",
    "        bdd=tf.reshape(bdd, (s,4))\n",
    "        bdd = tf.concat([bdd,c],axis=0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        if (i==0):\n",
    "            true_boxes =bdd\n",
    "        else:\n",
    "            true_boxes = tf.concat([true_boxes,bdd], axis=0)  \n",
    "    \n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    print(\"best_ious\", tf.reduce_max(best_ious))\n",
    "    \n",
    "    obj_mask = tf.zeros(mask_shape)\n",
    "    obj_mask = tf.cast((best_ious < 0.6),dtype=tf.float32) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    obj_mask = obj_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "\n",
    "    print(\"sum obj_mask\",tf.reduce_sum(obj_mask))\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    ### is 1 when there is a particular class is predicted, else 0.\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    class_weights = np.ones(NB_CLASS, dtype='float32')\n",
    "    class_mask = y_true[..., 4] * tf.gather(class_weights, true_box_class) * CLASS_SCALE\n",
    "    print(\"sum class_mask\",tf.reduce_sum(class_mask))\n",
    "    \n",
    "    nb_coord_box = tf.reduce_sum(tf.cast((coord_mask > 0.0),dtype=tf.float32))\n",
    "    nb_obj_box  = tf.reduce_sum(tf.cast((obj_mask  > 0.0),dtype=tf.float32))\n",
    "    nb_class_box = tf.reduce_sum(tf.cast((class_mask > 0.0),dtype=tf.float32))\n",
    "    print(\"nb_coord_box\",nb_coord_box)\n",
    "    print(\"nb_obj_box\",nb_obj_box)\n",
    "    print(\"nb_class_box\",nb_class_box) \n",
    "      \n",
    "    ### loss\n",
    "    loss_xy    = tf.reduce_sum(coord_mask * tf.square(true_box_xy - pred_box_xy)) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(coord_mask * tf.square(tf.sqrt(tf.abs(true_box_wh)) - tf.sqrt(tf.abs(pred_box_wh)))) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_obj   = tf.reduce_sum(obj_mask * tf.square(true_box_obj-pred_box_obj)) / (nb_obj_box + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(class_mask * loss_class) / (nb_class_box + 1e-6)\n",
    "\n",
    "    print(\"loss_xy\",loss_xy.shape)\n",
    "    print(\"sum loss_xy\",tf.reduce_sum(loss_xy))\n",
    "    \n",
    "    print(\"loss_wh\",loss_wh.shape)\n",
    "    print(\"sum loss_wh\",tf.reduce_sum(loss_wh))\n",
    "    \n",
    "    print(\"loss_obj\",loss_obj.shape)\n",
    "    print(\"sum loss_obj\",tf.reduce_sum(loss_obj))\n",
    "        \n",
    "    print(\"loss_class\",loss_class.shape)\n",
    "    print(\"sum loss_class\",tf.reduce_sum(loss_class))\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_obj + loss_class\n",
    "    print(\"loss\",loss.shape)\n",
    "    print()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = tf.keras.optimizers.SGD.RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Eager execution: False\n",
      "Keras version: 2.2.4-tf\n",
      "(None, 13, 13, 255)\n",
      "grid_h, grid_w 13 13\n",
      "mask_shape Tensor(\"loss/BN_15_loss/custom_loss/strided_slice:0\", shape=(4,), dtype=int32)\n",
      "y_true (32, 13, 13, 3, 85)\n",
      "sum coord_mask Tensor(\"loss/BN_15_loss/custom_loss/Sum:0\", shape=(), dtype=float32)\n",
      "best_ious Tensor(\"loss/BN_15_loss/custom_loss/Max_1:0\", shape=(), dtype=float32)\n",
      "sum obj_mask Tensor(\"loss/BN_15_loss/custom_loss/Sum_1:0\", shape=(), dtype=float32)\n",
      "sum class_mask Tensor(\"loss/BN_15_loss/custom_loss/Sum_2:0\", shape=(), dtype=float32)\n",
      "nb_coord_box Tensor(\"loss/BN_15_loss/custom_loss/Sum_3:0\", shape=(), dtype=float32)\n",
      "nb_obj_box Tensor(\"loss/BN_15_loss/custom_loss/Sum_4:0\", shape=(), dtype=float32)\n",
      "nb_class_box Tensor(\"loss/BN_15_loss/custom_loss/Sum_5:0\", shape=(), dtype=float32)\n",
      "loss_xy ()\n",
      "sum loss_xy Tensor(\"loss/BN_15_loss/custom_loss/Sum_10:0\", shape=(), dtype=float32)\n",
      "loss_wh ()\n",
      "sum loss_wh Tensor(\"loss/BN_15_loss/custom_loss/Sum_11:0\", shape=(), dtype=float32)\n",
      "loss_obj ()\n",
      "sum loss_obj Tensor(\"loss/BN_15_loss/custom_loss/Sum_12:0\", shape=(), dtype=float32)\n",
      "loss_class ()\n",
      "sum loss_class Tensor(\"loss/BN_15_loss/custom_loss/Sum_13:0\", shape=(), dtype=float32)\n",
      "loss ()\n",
      "\n",
      "TensorFlow version: 2.1.0\n",
      "Eager execution: False\n",
      "Keras version: 2.2.4-tf\n",
      "(None, 26, 26, 255)\n",
      "grid_h, grid_w 26 26\n",
      "mask_shape Tensor(\"loss/BN_22_loss/custom_loss/strided_slice:0\", shape=(4,), dtype=int32)\n",
      "y_true (32, 26, 26, 3, 85)\n",
      "sum coord_mask Tensor(\"loss/BN_22_loss/custom_loss/Sum:0\", shape=(), dtype=float32)\n",
      "best_ious Tensor(\"loss/BN_22_loss/custom_loss/Max_1:0\", shape=(), dtype=float32)\n",
      "sum obj_mask Tensor(\"loss/BN_22_loss/custom_loss/Sum_1:0\", shape=(), dtype=float32)\n",
      "sum class_mask Tensor(\"loss/BN_22_loss/custom_loss/Sum_2:0\", shape=(), dtype=float32)\n",
      "nb_coord_box Tensor(\"loss/BN_22_loss/custom_loss/Sum_3:0\", shape=(), dtype=float32)\n",
      "nb_obj_box Tensor(\"loss/BN_22_loss/custom_loss/Sum_4:0\", shape=(), dtype=float32)\n",
      "nb_class_box Tensor(\"loss/BN_22_loss/custom_loss/Sum_5:0\", shape=(), dtype=float32)\n",
      "loss_xy ()\n",
      "sum loss_xy Tensor(\"loss/BN_22_loss/custom_loss/Sum_10:0\", shape=(), dtype=float32)\n",
      "loss_wh ()\n",
      "sum loss_wh Tensor(\"loss/BN_22_loss/custom_loss/Sum_11:0\", shape=(), dtype=float32)\n",
      "loss_obj ()\n",
      "sum loss_obj Tensor(\"loss/BN_22_loss/custom_loss/Sum_12:0\", shape=(), dtype=float32)\n",
      "loss_class ()\n",
      "sum loss_class Tensor(\"loss/BN_22_loss/custom_loss/Sum_13:0\", shape=(), dtype=float32)\n",
      "loss ()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model using the custom loss function defined above\n",
    "yolo_model.compile(loss=custom_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Starting train\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"Stop train\")\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(\"--Start epoch {}\".format(epoch))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"--End epoch {}, the average training loss is {:7.2f}, testing loss is {:7.2f}\".format(epoch, logs[\"loss\"], logs[\"val_loss\"]))        \n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        print(\"---Start training batch {}, size {}\".format(batch,logs[\"size\"]))\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\"---End training batch {}, total loss is {:7.2f}, loss (13*13) is {:7.2f}, loss (26*26) is {:7.2f}\"\n",
    "              .format(batch, logs[\"loss\"],logs[\"BN_15_loss\"],logs[\"BN_22_loss\"]))      \n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        print(\"-Start testing\")\n",
    "        \n",
    "    def on_test_end(self, logs=None):\n",
    "        print(\"-Stop testing\")\n",
    "    \n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        print(\"---Start testing batch {}, size {}\".format(batch,logs[\"size\"]))\n",
    "        \n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print(\"---End testing batch {}, total loss is {:7.2f}, loss (13*13) is {:7.2f}, loss (26*26) is {:7.2f}\"\n",
    "              .format(batch, logs[\"loss\"],logs[\"BN_15_loss\"],logs[\"BN_22_loss\"]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 320 samples\n",
      "Starting train\n",
      "Epoch 1/10\n",
      "--Start epoch 0\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is  114.82, loss (13*13) is  100.61, loss (26*26) is   14.21\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   58.52, loss (13*13) is   75.88, loss (26*26) is   10.79\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   46.02, loss (13*13) is   63.75, loss (26*26) is    9.37\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   38.53, loss (13*13) is   55.61, loss (26*26) is    8.86\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   29.67, loss (13*13) is   49.24, loss (26*26) is    8.27\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   32.37, loss (13*13) is   45.39, loss (26*26) is    7.93\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   30.74, loss (13*13) is   42.44, loss (26*26) is    7.65\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   26.68, loss (13*13) is   39.75, loss (26*26) is    7.42\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   32.04, loss (13*13) is   38.25, loss (26*26) is    7.24\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   20.11, loss (13*13) is   35.91, loss (26*26) is    7.04\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   20.50, loss (13*13) is   34.01, loss (26*26) is    6.90\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   27.44, loss (13*13) is   33.00, loss (26*26) is    6.79\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   22.65, loss (13*13) is   31.81, loss (26*26) is    6.66\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   19.98, loss (13*13) is   30.59, loss (26*26) is    6.55\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   23.78, loss (13*13) is   29.81, loss (26*26) is    6.45\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   26.78, loss (13*13) is   29.30, loss (26*26) is    6.37\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   17.71, loss (13*13) is   28.33, loss (26*26) is    6.28\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   18.70, loss (13*13) is   27.53, loss (26*26) is    6.20\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   25.55, loss (13*13) is   27.16, loss (26*26) is    6.13\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   27.44, loss (13*13) is   26.91, loss (26*26) is    6.09\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   61.34, loss (13*13) is   44.11, loss (26*26) is   17.23\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   57.50, loss (13*13) is   47.53, loss (26*26) is   11.90\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is 1185.82, loss (13*13) is  424.21, loss (26*26) is   10.68\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   37.42, loss (13*13) is  326.13, loss (26*26) is    9.39\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   18.82, loss (13*13) is  263.41, loss (26*26) is    8.77\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   14.23, loss (13*13) is  221.01, loss (26*26) is    8.18\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   17.99, loss (13*13) is  191.24, loss (26*26) is    7.78\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   18.53, loss (13*13) is  168.82, loss (26*26) is    7.64\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   22.41, loss (13*13) is  151.96, loss (26*26) is    7.38\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is  115.53, loss (13*13) is  147.44, loss (26*26) is    7.52\n",
      "-Stop testing\n",
      " - 368s - loss: 33.0013 - BN_15_loss: 26.9114 - BN_22_loss: 6.0898 - val_loss: 154.9603 - val_BN_15_loss: 147.4401 - val_BN_22_loss: 7.5202\n",
      "--End epoch 0, the average training loss is   33.00, testing loss is  154.96\n",
      "Epoch 2/10\n",
      "--Start epoch 1\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   19.56, loss (13*13) is   14.33, loss (26*26) is    5.23\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   19.80, loss (13*13) is   14.69, loss (26*26) is    4.99\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   18.88, loss (13*13) is   14.49, loss (26*26) is    4.92\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   19.95, loss (13*13) is   14.70, loss (26*26) is    4.85\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   15.72, loss (13*13) is   13.96, loss (26*26) is    4.82\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   21.56, loss (13*13) is   14.40, loss (26*26) is    4.84\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   20.17, loss (13*13) is   14.58, loss (26*26) is    4.80\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   19.12, loss (13*13) is   14.56, loss (26*26) is    4.78\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   17.77, loss (13*13) is   14.41, loss (26*26) is    4.76\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   17.65, loss (13*13) is   14.27, loss (26*26) is    4.75\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   19.31, loss (13*13) is   14.31, loss (26*26) is    4.73\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   17.40, loss (13*13) is   14.18, loss (26*26) is    4.73\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   18.24, loss (13*13) is   14.14, loss (26*26) is    4.72\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   18.73, loss (13*13) is   14.13, loss (26*26) is    4.72\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   20.47, loss (13*13) is   14.24, loss (26*26) is    4.71\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   18.58, loss (13*13) is   14.22, loss (26*26) is    4.71\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   20.02, loss (13*13) is   14.28, loss (26*26) is    4.71\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   16.33, loss (13*13) is   14.15, loss (26*26) is    4.69\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   16.75, loss (13*13) is   14.06, loss (26*26) is    4.68\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   18.81, loss (13*13) is   14.07, loss (26*26) is    4.67\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   31.99, loss (13*13) is   22.75, loss (26*26) is    9.24\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   31.70, loss (13*13) is   24.31, loss (26*26) is    7.53\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is  489.09, loss (13*13) is  176.55, loss (26*26) is    7.71\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is  129.97, loss (13*13) is  163.62, loss (26*26) is    7.07\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   18.00, loss (13*13) is  133.32, loss (26*26) is    6.83\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   12.91, loss (13*13) is  112.44, loss (26*26) is    6.51\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   17.35, loss (13*13) is   98.13, loss (26*26) is    6.30\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   15.62, loss (13*13) is   87.06, loss (26*26) is    6.27\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   15.84, loss (13*13) is   78.61, loss (26*26) is    6.11\n",
      "---Start testing batch 9, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 9, total loss is   61.48, loss (13*13) is   76.21, loss (26*26) is    6.19\n",
      "-Stop testing\n",
      " - 159s - loss: 18.7415 - BN_15_loss: 14.0675 - BN_22_loss: 4.6740 - val_loss: 82.3960 - val_BN_15_loss: 76.2093 - val_BN_22_loss: 6.1867\n",
      "--End epoch 1, the average training loss is   18.74, testing loss is   82.40\n",
      "Epoch 3/10\n",
      "--Start epoch 2\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   16.87, loss (13*13) is   12.43, loss (26*26) is    4.44\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   14.36, loss (13*13) is   11.14, loss (26*26) is    4.47\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   13.96, loss (13*13) is   10.66, loss (26*26) is    4.41\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   19.98, loss (13*13) is   11.85, loss (26*26) is    4.44\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   19.74, loss (13*13) is   12.52, loss (26*26) is    4.46\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   18.19, loss (13*13) is   12.72, loss (26*26) is    4.47\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   14.88, loss (13*13) is   12.40, loss (26*26) is    4.46\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   16.64, loss (13*13) is   12.38, loss (26*26) is    4.45\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   14.76, loss (13*13) is   12.16, loss (26*26) is    4.44\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   17.29, loss (13*13) is   12.23, loss (26*26) is    4.43\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   16.22, loss (13*13) is   12.19, loss (26*26) is    4.43\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   15.72, loss (13*13) is   12.12, loss (26*26) is    4.43\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   16.14, loss (13*13) is   12.10, loss (26*26) is    4.42\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   15.57, loss (13*13) is   12.04, loss (26*26) is    4.42\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   14.34, loss (13*13) is   11.90, loss (26*26) is    4.41\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   16.93, loss (13*13) is   11.94, loss (26*26) is    4.41\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   16.18, loss (13*13) is   11.93, loss (26*26) is    4.41\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   15.80, loss (13*13) is   11.90, loss (26*26) is    4.41\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   14.76, loss (13*13) is   11.82, loss (26*26) is    4.41\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   12.97, loss (13*13) is   11.66, loss (26*26) is    4.40\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   39.30, loss (13*13) is   30.53, loss (26*26) is    8.77\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   36.71, loss (13*13) is   30.88, loss (26*26) is    7.12\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is  344.56, loss (13*13) is  132.82, loss (26*26) is    7.37\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is  219.67, loss (13*13) is  153.29, loss (26*26) is    6.77\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   17.21, loss (13*13) is  125.01, loss (26*26) is    6.48\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   13.40, loss (13*13) is  105.65, loss (26*26) is    6.16\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   20.47, loss (13*13) is   92.78, loss (26*26) is    5.98\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   15.47, loss (13*13) is   82.45, loss (26*26) is    5.90\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   19.44, loss (13*13) is   74.94, loss (26*26) is    5.75\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   71.68, loss (13*13) is   74.02, loss (26*26) is    5.77\n",
      "-Stop testing\n",
      " - 142s - loss: 16.0649 - BN_15_loss: 11.6634 - BN_22_loss: 4.4015 - val_loss: 79.7890 - val_BN_15_loss: 74.0232 - val_BN_22_loss: 5.7658\n",
      "--End epoch 2, the average training loss is   16.06, testing loss is   79.79\n",
      "Epoch 4/10\n",
      "--Start epoch 3\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   15.04, loss (13*13) is   10.71, loss (26*26) is    4.33\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   14.12, loss (13*13) is   10.26, loss (26*26) is    4.32\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   14.66, loss (13*13) is   10.29, loss (26*26) is    4.32\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   12.46, loss (13*13) is    9.78, loss (26*26) is    4.29\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   14.88, loss (13*13) is    9.94, loss (26*26) is    4.29\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   13.52, loss (13*13) is    9.84, loss (26*26) is    4.28\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   13.18, loss (13*13) is    9.70, loss (26*26) is    4.28\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   17.05, loss (13*13) is   10.07, loss (26*26) is    4.29\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   11.60, loss (13*13) is    9.77, loss (26*26) is    4.28\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   14.95, loss (13*13) is    9.87, loss (26*26) is    4.27\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   14.72, loss (13*13) is    9.93, loss (26*26) is    4.27\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   16.70, loss (13*13) is   10.13, loss (26*26) is    4.28\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   12.92, loss (13*13) is   10.02, loss (26*26) is    4.27\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   11.85, loss (13*13) is    9.85, loss (26*26) is    4.27\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   14.57, loss (13*13) is    9.89, loss (26*26) is    4.26\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   12.24, loss (13*13) is    9.77, loss (26*26) is    4.26\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   12.95, loss (13*13) is    9.72, loss (26*26) is    4.25\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   13.23, loss (13*13) is    9.68, loss (26*26) is    4.25\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   15.38, loss (13*13) is    9.75, loss (26*26) is    4.25\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   13.36, loss (13*13) is    9.72, loss (26*26) is    4.25\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   28.16, loss (13*13) is   20.49, loss (26*26) is    7.66\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   20.05, loss (13*13) is   17.64, loss (26*26) is    6.46\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is  151.91, loss (13*13) is   59.87, loss (26*26) is    6.83\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is  113.25, loss (13*13) is   71.98, loss (26*26) is    6.36\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   14.42, loss (13*13) is   59.44, loss (26*26) is    6.11\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   13.51, loss (13*13) is   51.05, loss (26*26) is    5.84\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   19.68, loss (13*13) is   45.87, loss (26*26) is    5.70\n",
      "---Start testing batch 7, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 7, total loss is   13.30, loss (13*13) is   41.16, loss (26*26) is    5.63\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   14.69, loss (13*13) is   37.71, loss (26*26) is    5.51\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   47.69, loss (13*13) is   38.17, loss (26*26) is    5.50\n",
      "-Stop testing\n",
      " - 141s - loss: 13.9685 - BN_15_loss: 9.7187 - BN_22_loss: 4.2499 - val_loss: 43.6663 - val_BN_15_loss: 38.1711 - val_BN_22_loss: 5.4952\n",
      "--End epoch 3, the average training loss is   13.97, testing loss is   43.67\n",
      "Epoch 5/10\n",
      "--Start epoch 4\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   12.93, loss (13*13) is    8.81, loss (26*26) is    4.11\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   12.36, loss (13*13) is    8.47, loss (26*26) is    4.17\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   11.55, loss (13*13) is    8.11, loss (26*26) is    4.17\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   11.94, loss (13*13) is    8.02, loss (26*26) is    4.17\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   10.99, loss (13*13) is    7.79, loss (26*26) is    4.16\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   12.94, loss (13*13) is    7.96, loss (26*26) is    4.16\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   11.34, loss (13*13) is    7.85, loss (26*26) is    4.15\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   12.54, loss (13*13) is    7.91, loss (26*26) is    4.16\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   15.01, loss (13*13) is    8.22, loss (26*26) is    4.18\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   12.01, loss (13*13) is    8.19, loss (26*26) is    4.17\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   12.60, loss (13*13) is    8.22, loss (26*26) is    4.16\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   12.37, loss (13*13) is    8.22, loss (26*26) is    4.16\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   15.35, loss (13*13) is    8.45, loss (26*26) is    4.16\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   12.36, loss (13*13) is    8.43, loss (26*26) is    4.16\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   11.48, loss (13*13) is    8.35, loss (26*26) is    4.17\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   11.24, loss (13*13) is    8.27, loss (26*26) is    4.16\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   11.94, loss (13*13) is    8.25, loss (26*26) is    4.16\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   11.72, loss (13*13) is    8.22, loss (26*26) is    4.15\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   11.99, loss (13*13) is    8.20, loss (26*26) is    4.15\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   13.33, loss (13*13) is    8.25, loss (26*26) is    4.15\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   25.10, loss (13*13) is   18.19, loss (26*26) is    6.92\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   19.22, loss (13*13) is   16.08, loss (26*26) is    6.08\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is  100.69, loss (13*13) is   41.96, loss (26*26) is    6.37\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   46.67, loss (13*13) is   41.89, loss (26*26) is    6.04\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   13.63, loss (13*13) is   35.21, loss (26*26) is    5.86\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   12.96, loss (13*13) is   30.74, loss (26*26) is    5.64\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   21.91, loss (13*13) is   28.78, loss (26*26) is    5.53\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   13.60, loss (13*13) is   26.23, loss (26*26) is    5.49\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   13.22, loss (13*13) is   24.27, loss (26*26) is    5.40\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   35.51, loss (13*13) is   24.88, loss (26*26) is    5.37\n",
      "-Stop testing\n",
      " - 130s - loss: 12.3997 - BN_15_loss: 8.2492 - BN_22_loss: 4.1505 - val_loss: 30.2508 - val_BN_15_loss: 24.8824 - val_BN_22_loss: 5.3685\n",
      "--End epoch 4, the average training loss is   12.40, testing loss is   30.25\n",
      "Epoch 6/10\n",
      "--Start epoch 5\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   10.49, loss (13*13) is    6.40, loss (26*26) is    4.09\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   11.76, loss (13*13) is    7.02, loss (26*26) is    4.11\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   11.07, loss (13*13) is    7.04, loss (26*26) is    4.07\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   12.09, loss (13*13) is    7.29, loss (26*26) is    4.06\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   11.28, loss (13*13) is    7.28, loss (26*26) is    4.06\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   11.20, loss (13*13) is    7.26, loss (26*26) is    4.06\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    9.76, loss (13*13) is    7.05, loss (26*26) is    4.04\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   12.29, loss (13*13) is    7.19, loss (26*26) is    4.06\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    9.82, loss (13*13) is    7.03, loss (26*26) is    4.05\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   10.27, loss (13*13) is    6.95, loss (26*26) is    4.05\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   10.01, loss (13*13) is    6.86, loss (26*26) is    4.05\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   10.99, loss (13*13) is    6.87, loss (26*26) is    4.05\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   10.74, loss (13*13) is    6.86, loss (26*26) is    4.05\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   10.13, loss (13*13) is    6.80, loss (26*26) is    4.05\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   12.04, loss (13*13) is    6.88, loss (26*26) is    4.05\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   11.14, loss (13*13) is    6.89, loss (26*26) is    4.05\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   10.28, loss (13*13) is    6.85, loss (26*26) is    4.05\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   10.40, loss (13*13) is    6.82, loss (26*26) is    4.05\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   10.12, loss (13*13) is    6.78, loss (26*26) is    4.05\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   11.66, loss (13*13) is    6.82, loss (26*26) is    4.05\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   29.44, loss (13*13) is   23.16, loss (26*26) is    6.28\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   18.32, loss (13*13) is   18.23, loss (26*26) is    5.65\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   60.32, loss (13*13) is   30.08, loss (26*26) is    5.95\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   41.07, loss (13*13) is   31.62, loss (26*26) is    5.67\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   15.53, loss (13*13) is   27.42, loss (26*26) is    5.52\n",
      "---Start testing batch 5, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 5, total loss is   13.29, loss (13*13) is   24.32, loss (26*26) is    5.34\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   21.87, loss (13*13) is   23.29, loss (26*26) is    5.26\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   13.44, loss (13*13) is   21.45, loss (26*26) is    5.21\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   12.13, loss (13*13) is   19.91, loss (26*26) is    5.13\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   31.27, loss (13*13) is   20.56, loss (26*26) is    5.11\n",
      "-Stop testing\n",
      " - 135s - loss: 10.8769 - BN_15_loss: 6.8240 - BN_22_loss: 4.0528 - val_loss: 25.6689 - val_BN_15_loss: 20.5584 - val_BN_22_loss: 5.1104\n",
      "--End epoch 5, the average training loss is   10.88, testing loss is   25.67\n",
      "Epoch 7/10\n",
      "--Start epoch 6\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   10.39, loss (13*13) is    6.43, loss (26*26) is    3.96\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   10.16, loss (13*13) is    6.29, loss (26*26) is    3.98\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   11.09, loss (13*13) is    6.58, loss (26*26) is    3.97\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   10.42, loss (13*13) is    6.55, loss (26*26) is    3.97\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   10.25, loss (13*13) is    6.50, loss (26*26) is    3.96\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    9.35, loss (13*13) is    6.32, loss (26*26) is    3.95\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   10.37, loss (13*13) is    6.32, loss (26*26) is    3.97\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   10.88, loss (13*13) is    6.40, loss (26*26) is    3.96\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   11.34, loss (13*13) is    6.50, loss (26*26) is    3.97\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   11.57, loss (13*13) is    6.61, loss (26*26) is    3.97\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    9.84, loss (13*13) is    6.54, loss (26*26) is    3.97\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    9.88, loss (13*13) is    6.49, loss (26*26) is    3.97\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   10.01, loss (13*13) is    6.46, loss (26*26) is    3.96\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   10.78, loss (13*13) is    6.49, loss (26*26) is    3.96\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    9.84, loss (13*13) is    6.44, loss (26*26) is    3.97\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    9.91, loss (13*13) is    6.41, loss (26*26) is    3.97\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    9.84, loss (13*13) is    6.38, loss (26*26) is    3.96\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   10.03, loss (13*13) is    6.36, loss (26*26) is    3.97\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    9.58, loss (13*13) is    6.33, loss (26*26) is    3.96\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   10.11, loss (13*13) is    6.32, loss (26*26) is    3.96\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   26.69, loss (13*13) is   20.50, loss (26*26) is    6.20\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   18.99, loss (13*13) is   17.31, loss (26*26) is    5.54\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   50.69, loss (13*13) is   26.47, loss (26*26) is    5.66\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   25.08, loss (13*13) is   24.93, loss (26*26) is    5.43\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   14.92, loss (13*13) is   21.98, loss (26*26) is    5.30\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   11.74, loss (13*13) is   19.54, loss (26*26) is    5.15\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   18.24, loss (13*13) is   18.69, loss (26*26) is    5.08\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   11.97, loss (13*13) is   17.26, loss (26*26) is    5.03\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   12.95, loss (13*13) is   16.28, loss (26*26) is    4.97\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   28.14, loss (13*13) is   16.99, loss (26*26) is    4.95\n",
      "-Stop testing\n",
      " - 139s - loss: 10.2806 - BN_15_loss: 6.3166 - BN_22_loss: 3.9640 - val_loss: 21.9413 - val_BN_15_loss: 16.9894 - val_BN_22_loss: 4.9519\n",
      "--End epoch 6, the average training loss is   10.28, testing loss is   21.94\n",
      "Epoch 8/10\n",
      "--Start epoch 7\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    9.36, loss (13*13) is    5.44, loss (26*26) is    3.93\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   10.13, loss (13*13) is    5.82, loss (26*26) is    3.92\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    9.22, loss (13*13) is    5.66, loss (26*26) is    3.91\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    9.80, loss (13*13) is    5.72, loss (26*26) is    3.91\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   10.17, loss (13*13) is    5.82, loss (26*26) is    3.92\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    9.22, loss (13*13) is    5.74, loss (26*26) is    3.91\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    9.63, loss (13*13) is    5.73, loss (26*26) is    3.91\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    9.08, loss (13*13) is    5.67, loss (26*26) is    3.91\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    9.55, loss (13*13) is    5.66, loss (26*26) is    3.91\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    9.30, loss (13*13) is    5.64, loss (26*26) is    3.91\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    9.22, loss (13*13) is    5.61, loss (26*26) is    3.91\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    9.41, loss (13*13) is    5.61, loss (26*26) is    3.90\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   10.12, loss (13*13) is    5.65, loss (26*26) is    3.91\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    9.16, loss (13*13) is    5.62, loss (26*26) is    3.91\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    9.68, loss (13*13) is    5.63, loss (26*26) is    3.91\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   10.06, loss (13*13) is    5.66, loss (26*26) is    3.91\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    9.12, loss (13*13) is    5.64, loss (26*26) is    3.91\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    9.00, loss (13*13) is    5.61, loss (26*26) is    3.90\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   10.44, loss (13*13) is    5.66, loss (26*26) is    3.90\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   10.28, loss (13*13) is    5.70, loss (26*26) is    3.90\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   17.40, loss (13*13) is   11.55, loss (26*26) is    5.85\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   13.33, loss (13*13) is    9.86, loss (26*26) is    5.50\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   29.78, loss (13*13) is   14.56, loss (26*26) is    5.61\n",
      "---Start testing batch 3, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 3, total loss is   18.24, loss (13*13) is   14.24, loss (26*26) is    5.45\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   12.67, loss (13*13) is   12.95, loss (26*26) is    5.34\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   11.07, loss (13*13) is   11.87, loss (26*26) is    5.21\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   14.11, loss (13*13) is   11.51, loss (26*26) is    5.15\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   11.35, loss (13*13) is   10.85, loss (26*26) is    5.14\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   10.89, loss (13*13) is   10.34, loss (26*26) is    5.09\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   19.57, loss (13*13) is   10.77, loss (26*26) is    5.07\n",
      "-Stop testing\n",
      " - 135s - loss: 9.5985 - BN_15_loss: 5.6952 - BN_22_loss: 3.9032 - val_loss: 15.8409 - val_BN_15_loss: 10.7748 - val_BN_22_loss: 5.0660\n",
      "--End epoch 7, the average training loss is    9.60, testing loss is   15.84\n",
      "Epoch 9/10\n",
      "--Start epoch 8\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    9.13, loss (13*13) is    5.25, loss (26*26) is    3.88\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    9.33, loss (13*13) is    5.34, loss (26*26) is    3.89\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.52, loss (13*13) is    5.13, loss (26*26) is    3.87\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.39, loss (13*13) is    5.00, loss (26*26) is    3.84\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    9.66, loss (13*13) is    5.15, loss (26*26) is    3.85\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    9.81, loss (13*13) is    5.29, loss (26*26) is    3.85\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.49, loss (13*13) is    5.20, loss (26*26) is    3.85\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    9.48, loss (13*13) is    5.25, loss (26*26) is    3.85\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   10.22, loss (13*13) is    5.38, loss (26*26) is    3.85\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    8.95, loss (13*13) is    5.35, loss (26*26) is    3.85\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    9.93, loss (13*13) is    5.42, loss (26*26) is    3.85\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    8.55, loss (13*13) is    5.36, loss (26*26) is    3.85\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    9.15, loss (13*13) is    5.35, loss (26*26) is    3.85\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    9.28, loss (13*13) is    5.35, loss (26*26) is    3.85\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    9.01, loss (13*13) is    5.34, loss (26*26) is    3.85\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    8.84, loss (13*13) is    5.32, loss (26*26) is    3.85\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    9.06, loss (13*13) is    5.31, loss (26*26) is    3.85\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    8.69, loss (13*13) is    5.29, loss (26*26) is    3.85\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    9.27, loss (13*13) is    5.30, loss (26*26) is    3.85\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.79, loss (13*13) is    5.28, loss (26*26) is    3.84\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   28.87, loss (13*13) is   23.16, loss (26*26) is    5.70\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   15.38, loss (13*13) is   16.82, loss (26*26) is    5.30\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   44.52, loss (13*13) is   24.06, loss (26*26) is    5.53\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   23.11, loss (13*13) is   22.65, loss (26*26) is    5.32\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   15.29, loss (13*13) is   20.24, loss (26*26) is    5.20\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   12.22, loss (13*13) is   18.15, loss (26*26) is    5.08\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   16.17, loss (13*13) is   17.21, loss (26*26) is    5.02\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   12.07, loss (13*13) is   15.98, loss (26*26) is    4.98\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   10.84, loss (13*13) is   14.91, loss (26*26) is    4.92\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   22.03, loss (13*13) is   15.15, loss (26*26) is    4.90\n",
      "-Stop testing\n",
      " - 134s - loss: 9.1274 - BN_15_loss: 5.2826 - BN_22_loss: 3.8448 - val_loss: 20.0491 - val_BN_15_loss: 15.1476 - val_BN_22_loss: 4.9015\n",
      "--End epoch 8, the average training loss is    9.13, testing loss is   20.05\n",
      "Epoch 10/10\n",
      "--Start epoch 9\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    8.36, loss (13*13) is    4.59, loss (26*26) is    3.76\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    8.41, loss (13*13) is    4.61, loss (26*26) is    3.77\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.35, loss (13*13) is    4.60, loss (26*26) is    3.77\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.28, loss (13*13) is    4.57, loss (26*26) is    3.78\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    8.87, loss (13*13) is    4.68, loss (26*26) is    3.77\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    8.69, loss (13*13) is    4.71, loss (26*26) is    3.78\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.04, loss (13*13) is    4.65, loss (26*26) is    3.77\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    8.34, loss (13*13) is    4.64, loss (26*26) is    3.77\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    8.98, loss (13*13) is    4.70, loss (26*26) is    3.78\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    8.37, loss (13*13) is    4.69, loss (26*26) is    3.78\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    8.80, loss (13*13) is    4.72, loss (26*26) is    3.78\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    8.58, loss (13*13) is    4.72, loss (26*26) is    3.78\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    8.26, loss (13*13) is    4.70, loss (26*26) is    3.78\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    8.12, loss (13*13) is    4.68, loss (26*26) is    3.78\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    8.90, loss (13*13) is    4.71, loss (26*26) is    3.78\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    8.66, loss (13*13) is    4.72, loss (26*26) is    3.78\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    8.41, loss (13*13) is    4.71, loss (26*26) is    3.78\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    8.33, loss (13*13) is    4.71, loss (26*26) is    3.78\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.75, loss (13*13) is    4.72, loss (26*26) is    3.78\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.33, loss (13*13) is    4.71, loss (26*26) is    3.78\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   28.79, loss (13*13) is   22.99, loss (26*26) is    5.80\n",
      "---Start testing batch 1, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 1, total loss is   15.04, loss (13*13) is   16.43, loss (26*26) is    5.48\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   36.99, loss (13*13) is   21.37, loss (26*26) is    5.57\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   18.07, loss (13*13) is   19.31, loss (26*26) is    5.41\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   15.30, loss (13*13) is   17.54, loss (26*26) is    5.29\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   11.49, loss (13*13) is   15.78, loss (26*26) is    5.16\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   16.99, loss (13*13) is   15.28, loss (26*26) is    5.11\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   12.25, loss (13*13) is   14.27, loss (26*26) is    5.09\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   10.88, loss (13*13) is   13.38, loss (26*26) is    5.05\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   19.36, loss (13*13) is   13.50, loss (26*26) is    5.02\n",
      "-Stop testing\n",
      " - 133s - loss: 8.4918 - BN_15_loss: 4.7090 - BN_22_loss: 3.7828 - val_loss: 18.5148 - val_BN_15_loss: 13.4975 - val_BN_22_loss: 5.0172\n",
      "--End epoch 9, the average training loss is    8.49, testing loss is   18.51\n",
      "Stop train\n",
      "elapsed seconds:  1628\n"
     ]
    }
   ],
   "source": [
    "# Fit the model including validation data\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "EScallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = yolo_model.fit(x=train_x, y=train_y, validation_data = (val_x,val_y), epochs= 10,batch_size =BATCH_SIZE, verbose=2, callbacks=[CustomCallback(),EScallback])\n",
    "\n",
    "elapsed = datetime.datetime.now()-start\n",
    "print(\"elapsed seconds: \",elapsed.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves\n",
    "from matplotlib import pyplot\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
