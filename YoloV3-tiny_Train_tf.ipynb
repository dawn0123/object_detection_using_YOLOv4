{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Eager execution: True\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D, MaxPool2D\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "\n",
    "\n",
    "NETWORK_W          = 416\n",
    "NETWORK_H          = 416\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# needs to be defined as activation class otherwise error\n",
    "# AttributeError: 'Activation' object has no attribute '__name__'    \n",
    "class Mish(Activation):\n",
    "    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Mish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'mish'\n",
    "\n",
    "\n",
    "def mysoftplus(x):\n",
    "\n",
    "    mask_min = tf.cast((x<-20.0),tf.float32)\n",
    "    ymin = mask_min*tf.math.exp(x)\n",
    "\n",
    "    mask_max = tf.cast((x>20.0),tf.float32)\n",
    "    ymax = mask_max*x\n",
    "    \n",
    "    mask= tf.cast((abs(x)<=20.0),tf.float32)\n",
    "    y = mask*tf.math.log(tf.math.exp(x) + 1.0)\n",
    "    \n",
    "    return(ymin+ymax+y)    \n",
    "        \n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return (x* tf.math.tanh(mysoftplus(x)))\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "get_custom_objects().update({'mish': Mish(mish)})\n",
    "\n",
    "def _conv_block(inp, convs, skip=False):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    \n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)), name='zerop_' + str(conv['layer_idx']))(x)  # peculiar padding as darknet prefer left and top\n",
    "        \n",
    "        x = Conv2D(conv['filter'], \n",
    "                   conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='convn_' + str(conv['layer_idx']) if conv['bnorm'] else 'conv_' + str(conv['layer_idx']),\n",
    "                   activation='mish' if conv['activ'] == 2 else None,\n",
    "                   use_bias=True)(x)\n",
    "                  \n",
    "        if conv['activ'] == 1: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "            \n",
    "    return add([skip_connection, x],  name='add_' + str(conv['layer_idx']+1)) if skip else x\n",
    "\n",
    "def make_yolov3_tiny_model():\n",
    "        \n",
    "    input_image = Input(shape=(NETWORK_H, NETWORK_W, 3), name='input_0')\n",
    "\n",
    "    # Layer  0\n",
    "    x = _conv_block(input_image, [{'filter': 16, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 0}])\n",
    "    \n",
    "    # Layer  1\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_1')(x)\n",
    "    \n",
    "    # Layer  2\n",
    "    x = _conv_block(x, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 2}])\n",
    "  \n",
    "    # Layer  3\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_3')(x)\n",
    "    \n",
    "    # Layer  4\n",
    "    x = _conv_block(x, [{'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 4}])   \n",
    "\n",
    "    # Layer  5\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_5')(x)\n",
    "    \n",
    "    # Layer  6\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 6}])   \n",
    "    \n",
    "    # Layer  7\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_7')(x)\n",
    "    \n",
    "    # Layer  8\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 8}])   \n",
    "    layer_8 = x\n",
    "    \n",
    "    # Layer  9\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=2, padding='same', name = 'max_9')(x)\n",
    "    \n",
    "    # Layer  10\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 10}])\n",
    "    layer_10 = x\n",
    "    \n",
    "    # Layer  11\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=1, padding='same', name = 'max_11')(x)\n",
    "    \n",
    "    # Layer  12\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 12}])\n",
    "\n",
    "    \n",
    "    ###########\n",
    "    \n",
    "    # Layer  13\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 13}]) \n",
    "    layer_13 = x\n",
    "        \n",
    "    # Layer  14\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 14}])     \n",
    "    \n",
    "    # Layer  15\n",
    "    x = _conv_block(x, [{'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 0, 'layer_idx': 15}])    \n",
    "    \n",
    "    # Layer  16\n",
    "    yolo_16 = x\n",
    "    \n",
    "    \n",
    "    # Layer  17\n",
    "    x = layer_13\n",
    "\n",
    "    # Layer  18\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 18}])\n",
    "   \n",
    "    # Layer  19\n",
    "    x = UpSampling2D(size=(2, 2), name = 'upsamp_19')(x)\n",
    "\n",
    "    # Layer  20\n",
    "    x = concatenate([layer_8, x],  name='concatenate_20')\n",
    "    \n",
    "    # Layer  21\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'activ': 1, 'layer_idx': 21}])     \n",
    "    \n",
    "    # Layer  22\n",
    "    x = _conv_block(x, [{'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': True, 'activ': 0, 'layer_idx': 22}])    \n",
    "    \n",
    "    # Layer  23\n",
    "    yolo_23 = x   \n",
    "                                      \n",
    "    model = Model(input_image, [yolo_16, yolo_23], name = 'Yolo_v3_tiny')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = make_yolov3_tiny_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import struct\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                print(\"reading 64 bytes\")\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                print(\"reading 32 bytes\")\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        count = 0\n",
    "        ncount = 0\n",
    "        for i in range(23):\n",
    "            try:\n",
    "\n",
    "                conv_layer = model.get_layer('convn_' + str(i))\n",
    "                filter = conv_layer.kernel.shape[-1]\n",
    "                nweights = np.prod(conv_layer.kernel.shape) # kernel*kernel*c*filter\n",
    "                \n",
    "                print(\"loading weights of convolution #\" + str(i)+ \"- nb parameters: \"+str(nweights+filter))             \n",
    "                \n",
    "                if i  in [15, 22]:\n",
    "                    print(\"Special processing for layer \"+ str(i))\n",
    "                    bias  = self.read_bytes(filter) # bias\n",
    "                    weights = self.read_bytes(nweights) # weights\n",
    "                \n",
    "                else:                    \n",
    "                    bias  = self.read_bytes(filter) # bias\n",
    "                    scale = self.read_bytes(filter) # scale\n",
    "                    mean  = self.read_bytes(filter) # mean\n",
    "                    var   = self.read_bytes(filter) # variance\n",
    "                    weights = self.read_bytes(nweights) # weights\n",
    "                    \n",
    "                    bias = bias - scale  * mean / (np.sqrt(var + 0.00001)) #normalize bias\n",
    "\n",
    "                    weights = np.reshape(weights,(filter,int(nweights/filter)))  #normalize weights\n",
    "                    A = scale / (np.sqrt(var + 0.00001))\n",
    "                    A= np.expand_dims(A,axis=0)\n",
    "                    weights = weights* A.T\n",
    "                    weights = np.reshape(weights,(nweights))\n",
    "                \n",
    "\n",
    "                weights = weights.reshape(list(reversed(conv_layer.get_weights()[0].shape)))                 \n",
    "                weights = weights.transpose([2,3,1,0])\n",
    "                \n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    a=conv_layer.set_weights([weights, bias])\n",
    "                else:    \n",
    "                    a=conv_layer.set_weights([weights])\n",
    "                \n",
    "                count = count+1\n",
    "                ncount = ncount+nweights+filter\n",
    "             \n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i)) \n",
    "        \n",
    "        print(count, \"Conv normalized layers loaded \", ncount, \" parameters\")\n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 64 bytes\n",
      "loading weights of convolution #0- nb parameters: 448\n",
      "no convolution #1\n",
      "loading weights of convolution #2- nb parameters: 4640\n",
      "no convolution #3\n",
      "loading weights of convolution #4- nb parameters: 18496\n",
      "no convolution #5\n",
      "loading weights of convolution #6- nb parameters: 73856\n",
      "no convolution #7\n",
      "loading weights of convolution #8- nb parameters: 295168\n",
      "no convolution #9\n",
      "loading weights of convolution #10- nb parameters: 1180160\n",
      "no convolution #11\n",
      "loading weights of convolution #12- nb parameters: 4719616\n",
      "loading weights of convolution #13- nb parameters: 262400\n",
      "loading weights of convolution #14- nb parameters: 1180160\n",
      "loading weights of convolution #15- nb parameters: 130815\n",
      "Special processing for layer 15\n",
      "no convolution #16\n",
      "no convolution #17\n",
      "loading weights of convolution #18- nb parameters: 32896\n",
      "no convolution #19\n",
      "no convolution #20\n",
      "loading weights of convolution #21- nb parameters: 884992\n",
      "loading weights of convolution #22- nb parameters: 65535\n",
      "Special processing for layer 22\n",
      "13 Conv normalized layers loaded  8849182  parameters\n"
     ]
    }
   ],
   "source": [
    "# Get and compute the weights\n",
    "weight_reader = WeightReader('models/yolo/yolov3-tiny.weights')\n",
    "weight_reader.load_weights(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle Windows\n",
      " Le num‚ro de s‚rie du volume est CCDC-AB26\n",
      "\n",
      " R‚pertoire de C:\\Users\\edh\\yolo4\\Yolov-4\\models\\yolo\n",
      "\n",
      "24/06/2020  23:17        35ÿ474ÿ900 yolov3-tiny.h5\n",
      "23/06/2020  13:41       257ÿ812ÿ724 yolov4.h5\n",
      "               2 fichier(s)      293ÿ287ÿ624 octets\n",
      "               0 R‚p(s)  282ÿ839ÿ724ÿ032 octets libres\n"
     ]
    }
   ],
   "source": [
    "# save the model to file\n",
    "! rm models\\yolo\\yolov3-tiny.h5\n",
    "\n",
    "model.save('models/yolo/yolov3-tiny.h5')\n",
    "! dir models\\yolo\\*.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edh\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "from keras.models import load_model, Model\n",
    "yolo_model = load_model(\"models/yolo/yolov3-tiny.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(labels_path):\n",
    "    with open(labels_path) as f:\n",
    "        labels = f.readlines()\n",
    "    labels = [c.strip() for c in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "nb labels:  80\n"
     ]
    }
   ],
   "source": [
    "# Load the labels\n",
    "labels = read_labels(\"models/yolo/coco_classes.txt\")\n",
    "print(labels)\n",
    "print(\"nb labels: \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_W        = 416\n",
    "NETWORK_H        = 416\n",
    "NB_BOX           = 3\n",
    "NB_CLASS         = len(labels)\n",
    "OBJ_THRESHOLD    = 0.3\n",
    "NMS_THRESHOLD    = 0.3\n",
    "grids = [(13,13), (26,26)]\n",
    "anchors = [[81,82,  135,169,  344,319], [10,14,  23,27,  37,58]]\n",
    "scales_x_y = [1.0, 1.0]\n",
    "\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 32\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "     \n",
    "        \n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "    \n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    " \n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    " \n",
    "        return self.label\n",
    " \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    " \n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "def convert(image_wh, box, grid_w, grid_h, Boxanchor, yolo_id):\n",
    "    dw = image_wh[0]/ grid_w\n",
    "    dh = image_wh[1]/ grid_h\n",
    "    center_x = (box[0] + box[1])/2.0\n",
    "    center_x = center_x / dw\n",
    "    center_y = (box[2] + box[3])/2.0\n",
    "    center_y = center_y / dh\n",
    "    \n",
    "    grid_x = int(np.floor(center_x))\n",
    "    grid_y = int(np.floor(center_y))\n",
    "    \n",
    "    if grid_x < grid_w and grid_y < grid_h:\n",
    "        w = (box[1] - box[0]) / dw\n",
    "        h = (box[3] - box[2]) / dh\n",
    "        \n",
    "        # find the anchor that best predicts this box\n",
    "        best_anchor = -1\n",
    "        max_iou     = -1\n",
    "    \n",
    "        shifted_box = BoundBox(0,0,w,h)\n",
    "    \n",
    "        for i in range(len(anchors[yolo_id])//2):\n",
    "            iou    = bbox_iou(shifted_box, Boxanchor[i])                   \n",
    "            if max_iou < iou:\n",
    "                best_anchor = i\n",
    "                max_iou     = iou\n",
    "    \n",
    "        return (center_x,center_y,w,h,grid_x,grid_y,best_anchor)\n",
    "    \n",
    "    else: # not compatible with the grid size\n",
    "        return (0,0,0,0,0,0,-1)\n",
    "    \n",
    "\n",
    "def convert_annotation(year, image_set, image_id, grid_w, grid_h, Boxanchor, yolo_id, VOC_path):\n",
    "    in_file = open(VOC_path+'VOC%s\\\\Annotations\\\\%s.xml'%(year, image_id))\n",
    "    out_file = open('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_%s\\\\%s.txt'%(year, image_set, yolo_id, image_id), 'w')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    image_w = int(size.find('width').text)\n",
    "    image_h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        cls = obj.find('name').text\n",
    "        if cls not in labels or int(difficult)==1:\n",
    "            continue\n",
    "        cls_id = labels.index(cls)\n",
    "        \n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((image_w,image_h), b, grid_w, grid_h, Boxanchor, yolo_id)\n",
    "        \n",
    "        if bb[-1] != -1:\n",
    "            out_file.write(str(cls_id) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')\n",
    "\n",
    "\n",
    "def build_label_files (year, image_set, VOC_path):\n",
    "    yolo_id = 0\n",
    "    \n",
    "    for grid_w, grid_h in grids:\n",
    "        print(\"grid :\",grid_w, grid_h)\n",
    "\n",
    "        Boxanchor= [BoundBox(0, 0, anchors[yolo_id][2*i], anchors[yolo_id][2*i+1]) for i in range(int(len(anchors[yolo_id])//2))]\n",
    "       \n",
    "        if not os.path.exists('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_%s\\\\' %(year, image_set, yolo_id)):\n",
    "            os.makedirs('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_%s\\\\' %(year, image_set, yolo_id))\n",
    "        \n",
    "        image_ids = open(VOC_path+'VOC%s\\\\ImageSets\\\\Main\\\\%s.txt'%(year, image_set)).read().strip().split()\n",
    "\n",
    "        for image_id in image_ids:\n",
    "            convert_annotation(year, image_set, image_id, grid_w, grid_h, Boxanchor, yolo_id, VOC_path)\n",
    "            \n",
    "        yolo_id+=1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid : 13 13\n",
      "grid : 26 26\n"
     ]
    }
   ],
   "source": [
    "# Build the label files for training\n",
    "VOC_path = '..\\\\train\\\\VOCdevkit\\\\'\n",
    "build_label_files ('2012', 'train', VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid : 13 13\n",
      "grid : 26 26\n"
     ]
    }
   ],
   "source": [
    "# Build the label files for validation\n",
    "build_label_files ('2012', 'val', VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, interpolation = 'bilinear', target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    \n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train (year, image_set, nb_train, VOC_path):\n",
    " \n",
    "    train_x  = np.zeros ((nb_train, NETWORK_H, NETWORK_W, 3), dtype=np.float32)\n",
    "    train_y0 = np.zeros ((nb_train, grids[0][1], grids[0][0], NB_BOX,(4+1+NB_CLASS)), dtype=np.float32)\n",
    "    train_y1 = np.zeros ((nb_train, grids[1][1], grids[1][0], NB_BOX,(4+1+NB_CLASS)), dtype=np.float32)\n",
    "    bc = 0 \n",
    "        \n",
    "    image_ids = open(VOC_path+'VOC%s\\\\ImageSets\\\\Main\\\\%s.txt'%(year, image_set)).read().strip().split()\n",
    "\n",
    "    \n",
    "    for image_id in image_ids:        \n",
    "        # Pre-process the image train_x\n",
    "        img_filename = VOC_path+'VOC%s\\\\JPEGImages\\\\%s.jpg'%(year, image_id)\n",
    "        image, image_w, image_h = load_image_pixels(img_filename, (NETWORK_W, NETWORK_H))\n",
    "        train_x[bc,:,:,:] = image\n",
    "        \n",
    "        # build true predict train_y0 and box b0\n",
    "        labels_file = open('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_0\\\\%s.txt'%(year, image_set, image_id), 'r')\n",
    "        \n",
    "        rec = np.fromfile(labels_file, dtype=np.float32, sep = \" \")\n",
    "        for i in range(len(rec)//8):\n",
    "            classid,x,y,w,h,grid_x,grid_y,best_anchor = rec[8*i:8*(i+1)]\n",
    "            train_y0[bc, int(grid_y),int(grid_x),int(best_anchor), 0:4] = x,y,w,h\n",
    "            train_y0[bc, int(grid_y),int(grid_x),int(best_anchor), 4] = 1.\n",
    "            train_y0[bc, int(grid_y),int(grid_x),int(best_anchor), 5+ int(classid)] = 0.9 #Class label smoothing, use 0.9 instead of 1.0 in order to mitigate overfitting.\n",
    "            \n",
    "        # build true predict train_y1 and box b1\n",
    "        labels_file = open('VOCdevkit\\\\VOC%s_%s\\\\tiny_labels_1\\\\%s.txt'%(year, image_set, image_id), 'r')\n",
    "        \n",
    "        rec = np.fromfile(labels_file, dtype=np.float32, sep = \" \")\n",
    "        true_box_index = 0\n",
    "        for i in range(len(rec)//8):\n",
    "            classid,x,y,w,h,grid_x,grid_y,best_anchor = rec[8*i:8*(i+1)]\n",
    "            train_y1[bc, int(grid_y),int(grid_x),int(best_anchor), 0:4] = x,y,w,h\n",
    "            train_y1[bc, int(grid_y),int(grid_x),int(best_anchor), 4] = 1.\n",
    "            train_y1[bc, int(grid_y),int(grid_x),int(best_anchor), 5+ int(classid)] = 0.9 #Class label smoothing, use 0.9 instead of 1.0 in order to mitigate overfitting.\n",
    "             \n",
    "        bc+=1\n",
    "        if bc == nb_train:\n",
    "            break\n",
    "            \n",
    "    return(train_x,  [train_y0,train_y1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the data for training\n",
    "VOC_path = '..\\\\train\\\\VOCdevkit\\\\'\n",
    "nb_data_for_training= 640\n",
    "train_x, train_y = build_train('2012', 'train', (nb_data_for_training//BATCH_SIZE)*BATCH_SIZE, VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the data for validation\n",
    "nb_data_for_validation= 320\n",
    "val_x, val_y = build_train('2012', 'val', (nb_data_for_validation//BATCH_SIZE)*BATCH_SIZE, VOC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "   \n",
    "    print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "    print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "    print(\"Keras version: {}\".format(tf.keras.__version__))\n",
    "   \n",
    "    print(y_pred.shape)\n",
    "    grid_h, grid_w = y_pred.shape[1:3] \n",
    "    print (\"grid_h, grid_w\",grid_h, grid_w)\n",
    "    \n",
    "    if grid_h == 13:\n",
    "        anchor = anchors[0]\n",
    "    else:    \n",
    "        anchor = anchors[1]     \n",
    "        \n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    print (\"mask_shape\",mask_shape)\n",
    "\n",
    "    \n",
    "    cell_x = tf.cast((tf.reshape(tf.tile(tf.range(grid_w), [grid_h]), (1, grid_h, grid_w, 1, 1))),dtype=tf.float32)\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, NB_BOX, 1])\n",
    "    \n",
    "    \n",
    "    ######  prediction\n",
    "    y_pred = tf.reshape(y_pred, (BATCH_SIZE, grid_h, grid_w, NB_BOX, NB_CLASS+5))\n",
    "\n",
    "    ### adjust x and y  \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) # x, y)\n",
    "    pred_box_xy = pred_box_xy + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(anchor, [1,1,1,NB_BOX,2])\n",
    "    \n",
    "    ### adjust objectness\n",
    "    pred_box_obj = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = tf.sigmoid(y_pred[..., 5:])\n",
    "    \n",
    "    \n",
    "    ######  true\n",
    "    y_true = tf.reshape(y_true, (BATCH_SIZE, grid_h, grid_w, NB_BOX, NB_CLASS+5))\n",
    "    print (\"y_true\", y_true.shape)\n",
    "\n",
    "    ### adjust x and y  \n",
    "    true_box_xy = y_true[..., :2] # x, y\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4]\n",
    "    \n",
    "    ### adjust objectness\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "\n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "\n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    \n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas + 1e-10\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "   \n",
    "    true_box_obj = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "\n",
    "    \n",
    "    \n",
    "    ######  coefficients   \n",
    "   \n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    ### is 1 when there is an object in the cell i, else 0.\n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    print(\"sum coord_mask\",tf.reduce_sum(coord_mask))\n",
    "    \n",
    "    ### objectness mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    for i in range(BATCH_SIZE):\n",
    "        bd = y_true[i,:,:,:,:4]\n",
    "        nozero = tf.not_equal(bd, tf.zeros((grid_h, grid_w, NB_BOX, 4)))\n",
    "        bdd = tf.boolean_mask(bd, nozero)\n",
    "        s=tf.squeeze(tf.size(bdd)//4)\n",
    "        c= tf.zeros((50-s,4))\n",
    "        bdd=tf.reshape(bdd, (s,4))\n",
    "        bdd = tf.concat([bdd,c],axis=0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        bdd = tf.expand_dims(bdd,0)\n",
    "        if (i==0):\n",
    "            true_boxes =bdd\n",
    "        else:\n",
    "            true_boxes = tf.concat([true_boxes,bdd], axis=0)  \n",
    "    \n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    print(\"best_ious\", tf.reduce_max(best_ious))\n",
    "    \n",
    "    obj_mask = tf.zeros(mask_shape)\n",
    "    obj_mask = tf.cast((best_ious < 0.6),dtype=tf.float32) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    obj_mask = obj_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "\n",
    "    print(\"sum obj_mask\",tf.reduce_sum(obj_mask))\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    ### is 1 when there is a particular class is predicted, else 0.\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    class_weights = np.ones(NB_CLASS, dtype='float32')\n",
    "    class_mask = y_true[..., 4] * tf.gather(class_weights, true_box_class) * CLASS_SCALE\n",
    "    print(\"sum class_mask\",tf.reduce_sum(class_mask))\n",
    "    \n",
    "    nb_coord_box = tf.reduce_sum(tf.cast((coord_mask > 0.0),dtype=tf.float32))\n",
    "    nb_obj_box  = tf.reduce_sum(tf.cast((obj_mask  > 0.0),dtype=tf.float32))\n",
    "    nb_class_box = tf.reduce_sum(tf.cast((class_mask > 0.0),dtype=tf.float32))\n",
    "    print(\"nb_coord_box\",nb_coord_box)\n",
    "    print(\"nb_obj_box\",nb_obj_box)\n",
    "    print(\"nb_class_box\",nb_class_box) \n",
    "      \n",
    "    ### loss\n",
    "    loss_xy    = tf.reduce_sum(coord_mask * tf.square(true_box_xy - pred_box_xy)) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(coord_mask * tf.square(tf.sqrt(tf.abs(true_box_wh)) - tf.sqrt(tf.abs(pred_box_wh)))) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_obj   = tf.reduce_sum(obj_mask * tf.square(true_box_obj-pred_box_obj)) / (nb_obj_box + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(class_mask * loss_class) / (nb_class_box + 1e-6)\n",
    "\n",
    "    print(\"loss_xy\",loss_xy.shape)\n",
    "    print(\"sum loss_xy\",tf.reduce_sum(loss_xy))\n",
    "    \n",
    "    print(\"loss_wh\",loss_wh.shape)\n",
    "    print(\"sum loss_wh\",tf.reduce_sum(loss_wh))\n",
    "    \n",
    "    print(\"loss_obj\",loss_obj.shape)\n",
    "    print(\"sum loss_obj\",tf.reduce_sum(loss_obj))\n",
    "        \n",
    "    print(\"loss_class\",loss_class.shape)\n",
    "    print(\"sum loss_class\",tf.reduce_sum(loss_class))\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_obj + loss_class\n",
    "    print(\"loss\",loss.shape)\n",
    "    print()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "#optimizer = tf.keras.optimizers.SGD.RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Eager execution: False\n",
      "Keras version: 2.2.4-tf\n",
      "(None, 13, 13, 255)\n",
      "grid_h, grid_w 13 13\n",
      "mask_shape Tensor(\"loss/convn_15_loss/custom_loss/strided_slice:0\", shape=(4,), dtype=int32)\n",
      "y_true (32, 13, 13, 3, 85)\n",
      "sum coord_mask Tensor(\"loss/convn_15_loss/custom_loss/Sum:0\", shape=(), dtype=float32)\n",
      "best_ious Tensor(\"loss/convn_15_loss/custom_loss/Max_1:0\", shape=(), dtype=float32)\n",
      "sum obj_mask Tensor(\"loss/convn_15_loss/custom_loss/Sum_1:0\", shape=(), dtype=float32)\n",
      "sum class_mask Tensor(\"loss/convn_15_loss/custom_loss/Sum_2:0\", shape=(), dtype=float32)\n",
      "nb_coord_box Tensor(\"loss/convn_15_loss/custom_loss/Sum_3:0\", shape=(), dtype=float32)\n",
      "nb_obj_box Tensor(\"loss/convn_15_loss/custom_loss/Sum_4:0\", shape=(), dtype=float32)\n",
      "nb_class_box Tensor(\"loss/convn_15_loss/custom_loss/Sum_5:0\", shape=(), dtype=float32)\n",
      "loss_xy ()\n",
      "sum loss_xy Tensor(\"loss/convn_15_loss/custom_loss/Sum_10:0\", shape=(), dtype=float32)\n",
      "loss_wh ()\n",
      "sum loss_wh Tensor(\"loss/convn_15_loss/custom_loss/Sum_11:0\", shape=(), dtype=float32)\n",
      "loss_obj ()\n",
      "sum loss_obj Tensor(\"loss/convn_15_loss/custom_loss/Sum_12:0\", shape=(), dtype=float32)\n",
      "loss_class ()\n",
      "sum loss_class Tensor(\"loss/convn_15_loss/custom_loss/Sum_13:0\", shape=(), dtype=float32)\n",
      "loss ()\n",
      "\n",
      "TensorFlow version: 2.1.0\n",
      "Eager execution: False\n",
      "Keras version: 2.2.4-tf\n",
      "(None, 26, 26, 255)\n",
      "grid_h, grid_w 26 26\n",
      "mask_shape Tensor(\"loss/convn_22_loss/custom_loss/strided_slice:0\", shape=(4,), dtype=int32)\n",
      "y_true (32, 26, 26, 3, 85)\n",
      "sum coord_mask Tensor(\"loss/convn_22_loss/custom_loss/Sum:0\", shape=(), dtype=float32)\n",
      "best_ious Tensor(\"loss/convn_22_loss/custom_loss/Max_1:0\", shape=(), dtype=float32)\n",
      "sum obj_mask Tensor(\"loss/convn_22_loss/custom_loss/Sum_1:0\", shape=(), dtype=float32)\n",
      "sum class_mask Tensor(\"loss/convn_22_loss/custom_loss/Sum_2:0\", shape=(), dtype=float32)\n",
      "nb_coord_box Tensor(\"loss/convn_22_loss/custom_loss/Sum_3:0\", shape=(), dtype=float32)\n",
      "nb_obj_box Tensor(\"loss/convn_22_loss/custom_loss/Sum_4:0\", shape=(), dtype=float32)\n",
      "nb_class_box Tensor(\"loss/convn_22_loss/custom_loss/Sum_5:0\", shape=(), dtype=float32)\n",
      "loss_xy ()\n",
      "sum loss_xy Tensor(\"loss/convn_22_loss/custom_loss/Sum_10:0\", shape=(), dtype=float32)\n",
      "loss_wh ()\n",
      "sum loss_wh Tensor(\"loss/convn_22_loss/custom_loss/Sum_11:0\", shape=(), dtype=float32)\n",
      "loss_obj ()\n",
      "sum loss_obj Tensor(\"loss/convn_22_loss/custom_loss/Sum_12:0\", shape=(), dtype=float32)\n",
      "loss_class ()\n",
      "sum loss_class Tensor(\"loss/convn_22_loss/custom_loss/Sum_13:0\", shape=(), dtype=float32)\n",
      "loss ()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model using the custom loss function defined above\n",
    "yolo_model.compile(loss=custom_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print(\"Starting train\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print(\"Stop train\")\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(\"--Start epoch {}\".format(epoch))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(\"--End epoch {}, the average training loss is {:7.2f}, testing loss is {:7.2f}\".format(epoch, logs[\"loss\"], logs[\"val_loss\"]))        \n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        print(\"---Start training batch {}, size {}\".format(batch,logs[\"size\"]))\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print(\"---End training batch {}, total loss is {:7.2f}, loss (13*13) is {:7.2f}, loss (26*26) is {:7.2f}\"\n",
    "              .format(batch, logs[\"loss\"],logs[\"convn_15_loss\"],logs[\"convn_22_loss\"]))      \n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        print(\"-Start testing\")\n",
    "        \n",
    "    def on_test_end(self, logs=None):\n",
    "        print(\"-Stop testing\")\n",
    "    \n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        print(\"---Start testing batch {}, size {}\".format(batch,logs[\"size\"]))\n",
    "        \n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print(\"---End testing batch {}, total loss is {:7.2f}, loss (13*13) is {:7.2f}, loss (26*26) is {:7.2f}\"\n",
    "              .format(batch, logs[\"loss\"],logs[\"convn_15_loss\"],logs[\"convn_22_loss\"]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640 samples, validate on 320 samples\n",
      "Starting train\n",
      "Epoch 1/10\n",
      "--Start epoch 0\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   64.00, loss (13*13) is   56.73, loss (26*26) is    7.27\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   60.23, loss (13*13) is   55.24, loss (26*26) is    6.87\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   58.76, loss (13*13) is   54.31, loss (26*26) is    6.68\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   53.07, loss (13*13) is   52.49, loss (26*26) is    6.52\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   51.04, loss (13*13) is   50.96, loss (26*26) is    6.46\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   48.89, loss (13*13) is   49.60, loss (26*26) is    6.40\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   42.21, loss (13*13) is   47.74, loss (26*26) is    6.29\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   41.86, loss (13*13) is   46.31, loss (26*26) is    6.20\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   34.28, loss (13*13) is   44.38, loss (26*26) is    6.10\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   32.18, loss (13*13) is   42.63, loss (26*26) is    6.02\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   30.85, loss (13*13) is   41.09, loss (26*26) is    5.95\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   28.62, loss (13*13) is   39.61, loss (26*26) is    5.89\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   22.02, loss (13*13) is   37.86, loss (26*26) is    5.84\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   20.00, loss (13*13) is   36.21, loss (26*26) is    5.79\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   18.98, loss (13*13) is   34.70, loss (26*26) is    5.76\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   15.57, loss (13*13) is   33.18, loss (26*26) is    5.73\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   13.79, loss (13*13) is   31.74, loss (26*26) is    5.70\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   11.96, loss (13*13) is   30.36, loss (26*26) is    5.66\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   11.02, loss (13*13) is   29.09, loss (26*26) is    5.62\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   10.83, loss (13*13) is   27.92, loss (26*26) is    5.59\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   10.75, loss (13*13) is    5.73, loss (26*26) is    5.03\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   10.78, loss (13*13) is    5.79, loss (26*26) is    4.98\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   11.44, loss (13*13) is    5.98, loss (26*26) is    5.02\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   10.89, loss (13*13) is    5.96, loss (26*26) is    5.01\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is   10.68, loss (13*13) is    5.94, loss (26*26) is    4.97\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   11.50, loss (13*13) is    6.04, loss (26*26) is    4.97\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   10.80, loss (13*13) is    6.02, loss (26*26) is    4.96\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   11.23, loss (13*13) is    6.06, loss (26*26) is    4.95\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   10.96, loss (13*13) is    6.06, loss (26*26) is    4.94\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is   10.98, loss (13*13) is    6.07, loss (26*26) is    4.93\n",
      "-Stop testing\n",
      " - 235s - loss: 33.5083 - convn_15_loss: 27.9216 - convn_22_loss: 5.5867 - val_loss: 11.0031 - val_convn_15_loss: 6.0706 - val_convn_22_loss: 4.9325\n",
      "--End epoch 0, the average training loss is   33.51, testing loss is   11.00\n",
      "Epoch 2/10\n",
      "--Start epoch 1\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   11.02, loss (13*13) is    6.17, loss (26*26) is    4.85\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is   10.87, loss (13*13) is    6.14, loss (26*26) is    4.80\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   11.76, loss (13*13) is    6.42, loss (26*26) is    4.80\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is   11.81, loss (13*13) is    6.56, loss (26*26) is    4.81\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is   11.93, loss (13*13) is    6.66, loss (26*26) is    4.82\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is   11.48, loss (13*13) is    6.69, loss (26*26) is    4.78\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is   12.00, loss (13*13) is    6.77, loss (26*26) is    4.78\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is   12.08, loss (13*13) is    6.84, loss (26*26) is    4.78\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is   11.84, loss (13*13) is    6.89, loss (26*26) is    4.75\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is   10.90, loss (13*13) is    6.86, loss (26*26) is    4.71\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is   11.04, loss (13*13) is    6.81, loss (26*26) is    4.71\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is   10.87, loss (13*13) is    6.77, loss (26*26) is    4.70\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is   10.83, loss (13*13) is    6.74, loss (26*26) is    4.68\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is   10.91, loss (13*13) is    6.70, loss (26*26) is    4.68\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is   10.16, loss (13*13) is    6.63, loss (26*26) is    4.67\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is   10.86, loss (13*13) is    6.61, loss (26*26) is    4.66\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is   10.55, loss (13*13) is    6.58, loss (26*26) is    4.65\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is   10.83, loss (13*13) is    6.56, loss (26*26) is    4.64\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is   10.36, loss (13*13) is    6.53, loss (26*26) is    4.63\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is   10.22, loss (13*13) is    6.49, loss (26*26) is    4.63\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is   10.83, loss (13*13) is    6.13, loss (26*26) is    4.70\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is   10.37, loss (13*13) is    5.95, loss (26*26) is    4.65\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is   10.64, loss (13*13) is    6.00, loss (26*26) is    4.61\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is   10.25, loss (13*13) is    5.95, loss (26*26) is    4.57\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    9.98, loss (13*13) is    5.90, loss (26*26) is    4.51\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is   10.49, loss (13*13) is    5.95, loss (26*26) is    4.48\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is   10.14, loss (13*13) is    5.91, loss (26*26) is    4.47\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is   10.34, loss (13*13) is    5.92, loss (26*26) is    4.46\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is   10.31, loss (13*13) is    5.92, loss (26*26) is    4.45\n",
      "---Start testing batch 9, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 9, total loss is   10.26, loss (13*13) is    5.91, loss (26*26) is    4.45\n",
      "-Stop testing\n",
      " - 261s - loss: 11.1157 - convn_15_loss: 6.4890 - convn_22_loss: 4.6267 - val_loss: 10.3621 - val_convn_15_loss: 5.9122 - val_convn_22_loss: 4.4499\n",
      "--End epoch 1, the average training loss is   11.12, testing loss is   10.36\n",
      "Epoch 3/10\n",
      "--Start epoch 2\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is   10.35, loss (13*13) is    5.87, loss (26*26) is    4.48\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    9.96, loss (13*13) is    5.80, loss (26*26) is    4.36\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is   10.00, loss (13*13) is    5.72, loss (26*26) is    4.39\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    9.92, loss (13*13) is    5.64, loss (26*26) is    4.42\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    9.65, loss (13*13) is    5.54, loss (26*26) is    4.44\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    9.94, loss (13*13) is    5.51, loss (26*26) is    4.46\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    9.60, loss (13*13) is    5.44, loss (26*26) is    4.47\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    9.56, loss (13*13) is    5.41, loss (26*26) is    4.46\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    9.32, loss (13*13) is    5.38, loss (26*26) is    4.44\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    9.45, loss (13*13) is    5.34, loss (26*26) is    4.43\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    9.22, loss (13*13) is    5.30, loss (26*26) is    4.43\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    9.48, loss (13*13) is    5.28, loss (26*26) is    4.43\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    9.04, loss (13*13) is    5.24, loss (26*26) is    4.42\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    9.65, loss (13*13) is    5.23, loss (26*26) is    4.42\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    9.52, loss (13*13) is    5.22, loss (26*26) is    4.43\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    9.05, loss (13*13) is    5.19, loss (26*26) is    4.42\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    9.22, loss (13*13) is    5.17, loss (26*26) is    4.42\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    9.18, loss (13*13) is    5.15, loss (26*26) is    4.41\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.96, loss (13*13) is    5.13, loss (26*26) is    4.40\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.82, loss (13*13) is    5.11, loss (26*26) is    4.39\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    9.50, loss (13*13) is    4.86, loss (26*26) is    4.64\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    9.34, loss (13*13) is    4.83, loss (26*26) is    4.59\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    9.73, loss (13*13) is    5.00, loss (26*26) is    4.52\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    9.11, loss (13*13) is    4.94, loss (26*26) is    4.48\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    8.84, loss (13*13) is    4.87, loss (26*26) is    4.43\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    9.18, loss (13*13) is    4.89, loss (26*26) is    4.39\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    9.13, loss (13*13) is    4.87, loss (26*26) is    4.39\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    9.10, loss (13*13) is    4.87, loss (26*26) is    4.37\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    9.17, loss (13*13) is    4.86, loss (26*26) is    4.37\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    9.05, loss (13*13) is    4.85, loss (26*26) is    4.36\n",
      "-Stop testing\n",
      " - 273s - loss: 9.4952 - convn_15_loss: 5.1076 - convn_22_loss: 4.3876 - val_loss: 9.2142 - val_convn_15_loss: 4.8497 - val_convn_22_loss: 4.3645\n",
      "--End epoch 2, the average training loss is    9.50, testing loss is    9.21\n",
      "Epoch 4/10\n",
      "--Start epoch 3\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    9.19, loss (13*13) is    4.94, loss (26*26) is    4.25\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    9.10, loss (13*13) is    4.81, loss (26*26) is    4.33\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.88, loss (13*13) is    4.78, loss (26*26) is    4.28\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.82, loss (13*13) is    4.76, loss (26*26) is    4.24\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    9.01, loss (13*13) is    4.74, loss (26*26) is    4.26\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    9.07, loss (13*13) is    4.72, loss (26*26) is    4.29\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.66, loss (13*13) is    4.68, loss (26*26) is    4.28\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    8.90, loss (13*13) is    4.64, loss (26*26) is    4.31\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    8.53, loss (13*13) is    4.60, loss (26*26) is    4.30\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    8.76, loss (13*13) is    4.59, loss (26*26) is    4.30\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    9.05, loss (13*13) is    4.58, loss (26*26) is    4.33\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    8.87, loss (13*13) is    4.56, loss (26*26) is    4.34\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    8.73, loss (13*13) is    4.55, loss (26*26) is    4.34\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    8.42, loss (13*13) is    4.52, loss (26*26) is    4.33\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    8.62, loss (13*13) is    4.51, loss (26*26) is    4.33\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    8.76, loss (13*13) is    4.50, loss (26*26) is    4.34\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    8.46, loss (13*13) is    4.48, loss (26*26) is    4.33\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    8.59, loss (13*13) is    4.47, loss (26*26) is    4.33\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.29, loss (13*13) is    4.46, loss (26*26) is    4.32\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.52, loss (13*13) is    4.44, loss (26*26) is    4.32\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    9.11, loss (13*13) is    4.57, loss (26*26) is    4.55\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    8.95, loss (13*13) is    4.51, loss (26*26) is    4.52\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.92, loss (13*13) is    4.54, loss (26*26) is    4.46\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    8.51, loss (13*13) is    4.46, loss (26*26) is    4.41\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    8.28, loss (13*13) is    4.39, loss (26*26) is    4.37\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    8.49, loss (13*13) is    4.38, loss (26*26) is    4.33\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.66, loss (13*13) is    4.37, loss (26*26) is    4.33\n",
      "---Start testing batch 7, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 7, total loss is    8.54, loss (13*13) is    4.37, loss (26*26) is    4.32\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    8.54, loss (13*13) is    4.36, loss (26*26) is    4.31\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.56, loss (13*13) is    4.35, loss (26*26) is    4.31\n",
      "-Stop testing\n",
      " - 181s - loss: 8.7610 - convn_15_loss: 4.4445 - convn_22_loss: 4.3165 - val_loss: 8.6556 - val_convn_15_loss: 4.3490 - val_convn_22_loss: 4.3066\n",
      "--End epoch 3, the average training loss is    8.76, testing loss is    8.66\n",
      "Epoch 5/10\n",
      "--Start epoch 4\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    8.47, loss (13*13) is    4.29, loss (26*26) is    4.18\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    8.59, loss (13*13) is    4.28, loss (26*26) is    4.25\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.09, loss (13*13) is    4.22, loss (26*26) is    4.16\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.45, loss (13*13) is    4.23, loss (26*26) is    4.17\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    8.66, loss (13*13) is    4.26, loss (26*26) is    4.19\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    8.27, loss (13*13) is    4.23, loss (26*26) is    4.19\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.33, loss (13*13) is    4.22, loss (26*26) is    4.18\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    8.54, loss (13*13) is    4.23, loss (26*26) is    4.20\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    8.33, loss (13*13) is    4.23, loss (26*26) is    4.19\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    8.40, loss (13*13) is    4.22, loss (26*26) is    4.19\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    8.28, loss (13*13) is    4.21, loss (26*26) is    4.19\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    8.47, loss (13*13) is    4.21, loss (26*26) is    4.19\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    8.45, loss (13*13) is    4.21, loss (26*26) is    4.20\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    8.38, loss (13*13) is    4.20, loss (26*26) is    4.20\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    8.20, loss (13*13) is    4.20, loss (26*26) is    4.20\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    8.24, loss (13*13) is    4.19, loss (26*26) is    4.20\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    8.48, loss (13*13) is    4.18, loss (26*26) is    4.21\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    8.64, loss (13*13) is    4.19, loss (26*26) is    4.22\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.58, loss (13*13) is    4.19, loss (26*26) is    4.22\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.76, loss (13*13) is    4.20, loss (26*26) is    4.23\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    8.90, loss (13*13) is    4.42, loss (26*26) is    4.48\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    8.74, loss (13*13) is    4.38, loss (26*26) is    4.43\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.66, loss (13*13) is    4.40, loss (26*26) is    4.37\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    8.39, loss (13*13) is    4.35, loss (26*26) is    4.33\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    8.18, loss (13*13) is    4.28, loss (26*26) is    4.29\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    8.28, loss (13*13) is    4.27, loss (26*26) is    4.26\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.52, loss (13*13) is    4.26, loss (26*26) is    4.26\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    8.31, loss (13*13) is    4.26, loss (26*26) is    4.24\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    8.34, loss (13*13) is    4.24, loss (26*26) is    4.24\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.44, loss (13*13) is    4.24, loss (26*26) is    4.24\n",
      "-Stop testing\n",
      " - 181s - loss: 8.4305 - convn_15_loss: 4.1988 - convn_22_loss: 4.2317 - val_loss: 8.4765 - val_convn_15_loss: 4.2350 - val_convn_22_loss: 4.2415\n",
      "--End epoch 4, the average training loss is    8.43, testing loss is    8.48\n",
      "Epoch 6/10\n",
      "--Start epoch 5\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    8.31, loss (13*13) is    4.23, loss (26*26) is    4.07\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    8.34, loss (13*13) is    4.15, loss (26*26) is    4.17\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.39, loss (13*13) is    4.14, loss (26*26) is    4.20\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.21, loss (13*13) is    4.11, loss (26*26) is    4.19\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    8.26, loss (13*13) is    4.13, loss (26*26) is    4.17\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    8.30, loss (13*13) is    4.12, loss (26*26) is    4.18\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.19, loss (13*13) is    4.11, loss (26*26) is    4.18\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    7.96, loss (13*13) is    4.09, loss (26*26) is    4.15\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    8.09, loss (13*13) is    4.09, loss (26*26) is    4.14\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    8.28, loss (13*13) is    4.09, loss (26*26) is    4.14\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    8.26, loss (13*13) is    4.10, loss (26*26) is    4.13\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    8.23, loss (13*13) is    4.10, loss (26*26) is    4.13\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    8.07, loss (13*13) is    4.09, loss (26*26) is    4.13\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    8.10, loss (13*13) is    4.09, loss (26*26) is    4.12\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    8.40, loss (13*13) is    4.09, loss (26*26) is    4.13\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    8.22, loss (13*13) is    4.09, loss (26*26) is    4.13\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    8.18, loss (13*13) is    4.09, loss (26*26) is    4.13\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    8.58, loss (13*13) is    4.10, loss (26*26) is    4.14\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.30, loss (13*13) is    4.10, loss (26*26) is    4.15\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.31, loss (13*13) is    4.10, loss (26*26) is    4.15\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    8.73, loss (13*13) is    4.33, loss (26*26) is    4.40\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    8.59, loss (13*13) is    4.29, loss (26*26) is    4.37\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.52, loss (13*13) is    4.31, loss (26*26) is    4.31\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    8.24, loss (13*13) is    4.26, loss (26*26) is    4.26\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    8.11, loss (13*13) is    4.20, loss (26*26) is    4.24\n",
      "---Start testing batch 5, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 5, total loss is    8.14, loss (13*13) is    4.18, loss (26*26) is    4.21\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.40, loss (13*13) is    4.18, loss (26*26) is    4.21\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    8.18, loss (13*13) is    4.18, loss (26*26) is    4.19\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    8.13, loss (13*13) is    4.15, loss (26*26) is    4.18\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.31, loss (13*13) is    4.15, loss (26*26) is    4.19\n",
      "-Stop testing\n",
      " - 182s - loss: 8.2483 - convn_15_loss: 4.0994 - convn_22_loss: 4.1489 - val_loss: 8.3359 - val_convn_15_loss: 4.1489 - val_convn_22_loss: 4.1869\n",
      "--End epoch 5, the average training loss is    8.25, testing loss is    8.34\n",
      "Epoch 7/10\n",
      "--Start epoch 6\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    7.96, loss (13*13) is    4.02, loss (26*26) is    3.94\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    8.22, loss (13*13) is    4.04, loss (26*26) is    4.05\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.08, loss (13*13) is    4.02, loss (26*26) is    4.06\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.11, loss (13*13) is    4.02, loss (26*26) is    4.07\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    8.01, loss (13*13) is    4.01, loss (26*26) is    4.06\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    8.20, loss (13*13) is    4.03, loss (26*26) is    4.07\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.15, loss (13*13) is    4.03, loss (26*26) is    4.07\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    8.32, loss (13*13) is    4.04, loss (26*26) is    4.10\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    7.86, loss (13*13) is    4.02, loss (26*26) is    4.08\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    7.86, loss (13*13) is    4.01, loss (26*26) is    4.07\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    8.09, loss (13*13) is    4.01, loss (26*26) is    4.07\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    8.10, loss (13*13) is    4.01, loss (26*26) is    4.07\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    8.19, loss (13*13) is    4.01, loss (26*26) is    4.07\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    8.14, loss (13*13) is    4.02, loss (26*26) is    4.07\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    8.06, loss (13*13) is    4.02, loss (26*26) is    4.07\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    8.05, loss (13*13) is    4.01, loss (26*26) is    4.07\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    8.07, loss (13*13) is    4.02, loss (26*26) is    4.07\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    8.31, loss (13*13) is    4.02, loss (26*26) is    4.08\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.09, loss (13*13) is    4.02, loss (26*26) is    4.08\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    8.15, loss (13*13) is    4.02, loss (26*26) is    4.08\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    8.50, loss (13*13) is    4.20, loss (26*26) is    4.31\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    8.46, loss (13*13) is    4.17, loss (26*26) is    4.32\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.40, loss (13*13) is    4.20, loss (26*26) is    4.26\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    8.11, loss (13*13) is    4.16, loss (26*26) is    4.21\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    8.05, loss (13*13) is    4.11, loss (26*26) is    4.20\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    8.04, loss (13*13) is    4.09, loss (26*26) is    4.17\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.30, loss (13*13) is    4.09, loss (26*26) is    4.17\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    8.06, loss (13*13) is    4.09, loss (26*26) is    4.15\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    7.97, loss (13*13) is    4.07, loss (26*26) is    4.14\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.19, loss (13*13) is    4.06, loss (26*26) is    4.15\n",
      "-Stop testing\n",
      " - 182s - loss: 8.1008 - convn_15_loss: 4.0223 - convn_22_loss: 4.0785 - val_loss: 8.2083 - val_convn_15_loss: 4.0616 - val_convn_22_loss: 4.1467\n",
      "--End epoch 6, the average training loss is    8.10, testing loss is    8.21\n",
      "Epoch 8/10\n",
      "--Start epoch 7\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    7.85, loss (13*13) is    3.92, loss (26*26) is    3.92\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    7.98, loss (13*13) is    3.92, loss (26*26) is    3.99\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    8.12, loss (13*13) is    3.94, loss (26*26) is    4.04\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    7.88, loss (13*13) is    3.93, loss (26*26) is    4.03\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    8.17, loss (13*13) is    3.95, loss (26*26) is    4.05\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    8.16, loss (13*13) is    3.95, loss (26*26) is    4.08\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    8.01, loss (13*13) is    3.94, loss (26*26) is    4.08\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    7.86, loss (13*13) is    3.94, loss (26*26) is    4.06\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    8.05, loss (13*13) is    3.95, loss (26*26) is    4.06\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    7.92, loss (13*13) is    3.95, loss (26*26) is    4.05\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    7.99, loss (13*13) is    3.96, loss (26*26) is    4.04\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    7.87, loss (13*13) is    3.95, loss (26*26) is    4.04\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    7.86, loss (13*13) is    3.94, loss (26*26) is    4.04\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    7.92, loss (13*13) is    3.94, loss (26*26) is    4.03\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    7.99, loss (13*13) is    3.94, loss (26*26) is    4.03\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    7.99, loss (13*13) is    3.94, loss (26*26) is    4.04\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    7.99, loss (13*13) is    3.94, loss (26*26) is    4.04\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    7.90, loss (13*13) is    3.94, loss (26*26) is    4.03\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    8.07, loss (13*13) is    3.94, loss (26*26) is    4.03\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    7.94, loss (13*13) is    3.95, loss (26*26) is    4.03\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    8.41, loss (13*13) is    4.12, loss (26*26) is    4.29\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    8.37, loss (13*13) is    4.09, loss (26*26) is    4.30\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.32, loss (13*13) is    4.12, loss (26*26) is    4.24\n",
      "---Start testing batch 3, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 3, total loss is    8.04, loss (13*13) is    4.09, loss (26*26) is    4.19\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    7.99, loss (13*13) is    4.05, loss (26*26) is    4.18\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    7.94, loss (13*13) is    4.03, loss (26*26) is    4.15\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.22, loss (13*13) is    4.03, loss (26*26) is    4.15\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    7.98, loss (13*13) is    4.02, loss (26*26) is    4.13\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    7.87, loss (13*13) is    4.01, loss (26*26) is    4.12\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.12, loss (13*13) is    4.00, loss (26*26) is    4.13\n",
      "-Stop testing\n",
      " - 182s - loss: 7.9762 - convn_15_loss: 3.9454 - convn_22_loss: 4.0307 - val_loss: 8.1272 - val_convn_15_loss: 4.0020 - val_convn_22_loss: 4.1252\n",
      "--End epoch 7, the average training loss is    7.98, testing loss is    8.13\n",
      "Epoch 9/10\n",
      "--Start epoch 8\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    8.26, loss (13*13) is    4.04, loss (26*26) is    4.22\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    7.95, loss (13*13) is    3.98, loss (26*26) is    4.13\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    7.80, loss (13*13) is    3.93, loss (26*26) is    4.07\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    8.03, loss (13*13) is    3.94, loss (26*26) is    4.07\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    7.86, loss (13*13) is    3.93, loss (26*26) is    4.05\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    7.84, loss (13*13) is    3.92, loss (26*26) is    4.03\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    7.86, loss (13*13) is    3.91, loss (26*26) is    4.03\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    7.85, loss (13*13) is    3.91, loss (26*26) is    4.02\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    7.78, loss (13*13) is    3.91, loss (26*26) is    4.01\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    7.83, loss (13*13) is    3.90, loss (26*26) is    4.01\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    7.91, loss (13*13) is    3.90, loss (26*26) is    4.01\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    7.73, loss (13*13) is    3.89, loss (26*26) is    4.00\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    7.96, loss (13*13) is    3.90, loss (26*26) is    4.00\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    8.05, loss (13*13) is    3.90, loss (26*26) is    4.00\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    7.84, loss (13*13) is    3.90, loss (26*26) is    4.00\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    7.95, loss (13*13) is    3.91, loss (26*26) is    4.00\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    7.77, loss (13*13) is    3.91, loss (26*26) is    3.99\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    7.95, loss (13*13) is    3.90, loss (26*26) is    4.00\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    7.72, loss (13*13) is    3.90, loss (26*26) is    4.00\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    7.78, loss (13*13) is    3.89, loss (26*26) is    4.00\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    8.33, loss (13*13) is    4.06, loss (26*26) is    4.27\n",
      "---Start testing batch 1, size 32\n",
      "---End testing batch 1, total loss is    8.30, loss (13*13) is    4.04, loss (26*26) is    4.28\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.27, loss (13*13) is    4.07, loss (26*26) is    4.23\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    7.99, loss (13*13) is    4.05, loss (26*26) is    4.17\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    7.92, loss (13*13) is    4.00, loss (26*26) is    4.16\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    7.89, loss (13*13) is    3.98, loss (26*26) is    4.13\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.13, loss (13*13) is    3.98, loss (26*26) is    4.14\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    7.93, loss (13*13) is    3.98, loss (26*26) is    4.12\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    7.83, loss (13*13) is    3.96, loss (26*26) is    4.10\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.05, loss (13*13) is    3.96, loss (26*26) is    4.11\n",
      "-Stop testing\n",
      " - 188s - loss: 7.8858 - convn_15_loss: 3.8906 - convn_22_loss: 3.9952 - val_loss: 8.0647 - val_convn_15_loss: 3.9565 - val_convn_22_loss: 4.1082\n",
      "--End epoch 8, the average training loss is    7.89, testing loss is    8.06\n",
      "Epoch 10/10\n",
      "--Start epoch 9\n",
      "---Start training batch 0, size 32\n",
      "---End training batch 0, total loss is    8.02, loss (13*13) is    3.94, loss (26*26) is    4.08\n",
      "---Start training batch 1, size 32\n",
      "---End training batch 1, total loss is    7.80, loss (13*13) is    3.91, loss (26*26) is    4.00\n",
      "---Start training batch 2, size 32\n",
      "---End training batch 2, total loss is    7.88, loss (13*13) is    3.90, loss (26*26) is    4.00\n",
      "---Start training batch 3, size 32\n",
      "---End training batch 3, total loss is    7.87, loss (13*13) is    3.88, loss (26*26) is    4.01\n",
      "---Start training batch 4, size 32\n",
      "---End training batch 4, total loss is    7.95, loss (13*13) is    3.88, loss (26*26) is    4.02\n",
      "---Start training batch 5, size 32\n",
      "---End training batch 5, total loss is    7.67, loss (13*13) is    3.86, loss (26*26) is    4.00\n",
      "---Start training batch 6, size 32\n",
      "---End training batch 6, total loss is    7.78, loss (13*13) is    3.86, loss (26*26) is    3.99\n",
      "---Start training batch 7, size 32\n",
      "---End training batch 7, total loss is    7.76, loss (13*13) is    3.86, loss (26*26) is    3.98\n",
      "---Start training batch 8, size 32\n",
      "---End training batch 8, total loss is    7.75, loss (13*13) is    3.85, loss (26*26) is    3.98\n",
      "---Start training batch 9, size 32\n",
      "---End training batch 9, total loss is    7.76, loss (13*13) is    3.85, loss (26*26) is    3.97\n",
      "---Start training batch 10, size 32\n",
      "---End training batch 10, total loss is    7.75, loss (13*13) is    3.85, loss (26*26) is    3.97\n",
      "---Start training batch 11, size 32\n",
      "---End training batch 11, total loss is    7.96, loss (13*13) is    3.85, loss (26*26) is    3.98\n",
      "---Start training batch 12, size 32\n",
      "---End training batch 12, total loss is    7.80, loss (13*13) is    3.85, loss (26*26) is    3.98\n",
      "---Start training batch 13, size 32\n",
      "---End training batch 13, total loss is    7.81, loss (13*13) is    3.85, loss (26*26) is    3.98\n",
      "---Start training batch 14, size 32\n",
      "---End training batch 14, total loss is    7.74, loss (13*13) is    3.84, loss (26*26) is    3.98\n",
      "---Start training batch 15, size 32\n",
      "---End training batch 15, total loss is    7.77, loss (13*13) is    3.85, loss (26*26) is    3.97\n",
      "---Start training batch 16, size 32\n",
      "---End training batch 16, total loss is    7.79, loss (13*13) is    3.84, loss (26*26) is    3.97\n",
      "---Start training batch 17, size 32\n",
      "---End training batch 17, total loss is    7.75, loss (13*13) is    3.84, loss (26*26) is    3.97\n",
      "---Start training batch 18, size 32\n",
      "---End training batch 18, total loss is    7.81, loss (13*13) is    3.85, loss (26*26) is    3.97\n",
      "---Start training batch 19, size 32\n",
      "---End training batch 19, total loss is    7.76, loss (13*13) is    3.84, loss (26*26) is    3.97\n",
      "-Start testing\n",
      "---Start testing batch 0, size 32\n",
      "---End testing batch 0, total loss is    8.25, loss (13*13) is    4.01, loss (26*26) is    4.23\n",
      "---Start testing batch 1, size 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---End testing batch 1, total loss is    8.27, loss (13*13) is    4.01, loss (26*26) is    4.25\n",
      "---Start testing batch 2, size 32\n",
      "---End testing batch 2, total loss is    8.16, loss (13*13) is    4.03, loss (26*26) is    4.20\n",
      "---Start testing batch 3, size 32\n",
      "---End testing batch 3, total loss is    7.95, loss (13*13) is    4.00, loss (26*26) is    4.15\n",
      "---Start testing batch 4, size 32\n",
      "---End testing batch 4, total loss is    7.90, loss (13*13) is    3.96, loss (26*26) is    4.15\n",
      "---Start testing batch 5, size 32\n",
      "---End testing batch 5, total loss is    7.88, loss (13*13) is    3.94, loss (26*26) is    4.12\n",
      "---Start testing batch 6, size 32\n",
      "---End testing batch 6, total loss is    8.08, loss (13*13) is    3.94, loss (26*26) is    4.13\n",
      "---Start testing batch 7, size 32\n",
      "---End testing batch 7, total loss is    7.92, loss (13*13) is    3.94, loss (26*26) is    4.11\n",
      "---Start testing batch 8, size 32\n",
      "---End testing batch 8, total loss is    7.80, loss (13*13) is    3.92, loss (26*26) is    4.10\n",
      "---Start testing batch 9, size 32\n",
      "---End testing batch 9, total loss is    8.02, loss (13*13) is    3.92, loss (26*26) is    4.10\n",
      "-Stop testing\n",
      " - 190s - loss: 7.8087 - convn_15_loss: 3.8436 - convn_22_loss: 3.9650 - val_loss: 8.0222 - val_convn_15_loss: 3.9207 - val_convn_22_loss: 4.1015\n",
      "--End epoch 9, the average training loss is    7.81, testing loss is    8.02\n",
      "Stop train\n",
      "elapsed seconds:  2067\n"
     ]
    }
   ],
   "source": [
    "# Fit the model including validation data\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "EScallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = yolo_model.fit(x=train_x, y=train_y, validation_data = (val_x,val_y), epochs= 10,batch_size =BATCH_SIZE, verbose=2, callbacks=[CustomCallback(),EScallback])\n",
    "\n",
    "elapsed = datetime.datetime.now()-start\n",
    "print(\"elapsed seconds: \",elapsed.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves\n",
    "from matplotlib import pyplot\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
